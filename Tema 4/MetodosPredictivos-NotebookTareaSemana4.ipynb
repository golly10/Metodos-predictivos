{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk9mtJJOegTX"
      },
      "source": [
        "# Métodos predictivos: tarea de asignación (semana 4)\n",
        "## Implementación propia del método de vecinos más cercanos. Comparación con otros métodos en *scikit-learn*.\n",
        "\n",
        "## Instrucciones\n",
        "En este notebook encontrarás los pasos necesarios para realizar la tarea de la 4ª semana de Métodos Predictivos del Máster en Ciencia de Datos.Lea detenidamente y siga los pasos indicados en las siguientes celdas, complete el código donde se indique ``# COMPLETAR AQUI``, respetando el formato o los nombres de funciones especificados.\n",
        "\n",
        "## Descripción de la tarea\n",
        "En esta tarea, el principal objetivo será realizar una implementación propia del método de k vecinos más cercanos (kNN), analizar su comportamiento mediante un estudio de sus parámetros, y por último compararlo con otros métodos de scikit-learn. La tarea consta de varios apartados:\n",
        "0. Carga y preparación de datos\n",
        "1. Implementar función de distancia (1 punto)\n",
        "2. Implementar kNN básico (2 puntos)\n",
        "3. Implementar kNN con pesos (1 punto)\n",
        "4. Estudio de los parámetros (0.75 puntos)\n",
        "5. Comparación con otros métodos (0.25 puntos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYvOzHcZtG89"
      },
      "source": [
        "Rellenar esta celda con los datos del alumno\n",
        "\n",
        "**Nombre**: Juan José\n",
        "\n",
        "**Apellidos**: Méndez Torrero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3dHp9YUe8RD"
      },
      "source": [
        "## 0. Carga y preparación de datos\n",
        "\n",
        "En primer lugar, vamos a cargar los datos que utilizaremos posteriormente para entrenar los distintos métodos de clasificación, incluyendo nuestra implementación de kNN.\n",
        "\n",
        "Vamos a utilizar un subconjunto del *dataset* [*Mice Protein Expression*](https://www.kaggle.com/ruslankl/mice-protein-expression). La versión de los datos que vamos a utilizar se encuentran en el siguiente [enlace](http://www.uco.es/users/jmoyano/MiceProteinExpression.csv). \n",
        "\n",
        "El conjunto de datos contiene los niveles de expresión de 77 proteínas medidas en el cortex cerebral de 8 tipos de ratones.\n",
        "Se realizaron hasta 15 medidas por ratón, incluyendo 38 ratones de control, y 34 trisómicos (síndrome de down); es decir, un total de 72 ratones. Por tanto, hay un total de 570 muestras (38x15) para ratones de control, y 510 para trisómicos (34x15). En total, el dataset contiene 1080 muestras, que pueden considerarse independientes.\n",
        "\n",
        "Existen 8 clases distintas, cada una descrita por 3 valores x-Y-z, relativos a genotipo, comportamiento, y tratamiento de los ratones:\n",
        "  - x: c (control) / t (trisomia)\n",
        "  - Y: CS (estimulados a aprender) / SC (no recibe estimulación)\n",
        "  - z: s (se le inyecta *saline*) / m (se le inyecta *memantine*) \n",
        "\n",
        "Para más información acerca de los datos puede consultar la [fuente](https://www.kaggle.com/ruslankl/mice-protein-expression).\n",
        "\n",
        "En la siguiente celda, cargaremos los datos directamente utilizando una [url](http://www.uco.es/users/jmoyano/MiceProteinExpression.csv) donde estén alojados, o descargandolos y añadiendolos a nuestro espacio de trabajo en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Zb8ISLewbTH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       MouseID  DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N  \\\n",
            "0        309_1  0.503644  0.747193  0.430175  2.816329  5.990152  0.218830   \n",
            "1        309_2  0.514617  0.689064  0.411770  2.789514  5.685038  0.211636   \n",
            "2        309_3  0.509183  0.730247  0.418309  2.687201  5.622059  0.209011   \n",
            "3        309_4  0.442107  0.617076  0.358626  2.466947  4.979503  0.222886   \n",
            "4        309_5  0.434940  0.617430  0.358802  2.365785  4.718679  0.213106   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1075  J3295_11  0.254860  0.463591  0.254860  2.092082  2.600035  0.211736   \n",
            "1076  J3295_12  0.272198  0.474163  0.251638  2.161390  2.801492  0.251274   \n",
            "1077  J3295_13  0.228700  0.395179  0.234118  1.733184  2.220852  0.220665   \n",
            "1078  J3295_14  0.221242  0.412894  0.243974  1.876347  2.384088  0.208897   \n",
            "1079  J3295_15  0.302626  0.461059  0.256564  2.092790  2.594348  0.251001   \n",
            "\n",
            "       pBRAF_N  pCAMKII_N   pCREB_N  ...     BAD_N  BCL2_N     pS6_N  \\\n",
            "0     0.177565   2.373744  0.232224  ...  0.122652     NaN  0.106305   \n",
            "1     0.172817   2.292150  0.226972  ...  0.116682     NaN  0.106592   \n",
            "2     0.175722   2.283337  0.230247  ...  0.118508     NaN  0.108303   \n",
            "3     0.176463   2.152301  0.207004  ...  0.132781     NaN  0.103184   \n",
            "4     0.173627   2.134014  0.192158  ...  0.129954     NaN  0.104784   \n",
            "...        ...        ...       ...  ...       ...     ...       ...   \n",
            "1075  0.171262   2.483740  0.207317  ...  0.190483     NaN  0.115806   \n",
            "1076  0.182496   2.512737  0.216339  ...  0.190463     NaN  0.113614   \n",
            "1077  0.161435   1.989723  0.185164  ...  0.216682     NaN  0.118948   \n",
            "1078  0.173623   2.086028  0.192044  ...  0.222263     NaN  0.125295   \n",
            "1079  0.191811   2.361816  0.223632  ...  0.227606     NaN  0.118899   \n",
            "\n",
            "       pCFOS_N     SYP_N  H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N   class  \n",
            "0     0.108336  0.427099   0.114783  0.131790  0.128186  1.675652  c-CS-m  \n",
            "1     0.104315  0.441581   0.111974  0.135103  0.131119  1.743610  c-CS-m  \n",
            "2     0.106219  0.435777   0.111883  0.133362  0.127431  1.926427  c-CS-m  \n",
            "3     0.111262  0.391691   0.130405  0.147444  0.146901  1.700563  c-CS-m  \n",
            "4     0.110694  0.434154   0.118481  0.140314  0.148380  1.839730  c-CS-m  \n",
            "...        ...       ...        ...       ...       ...       ...     ...  \n",
            "1075  0.183324  0.374088   0.318782  0.204660  0.328327  1.364823  t-SC-s  \n",
            "1076  0.175674  0.375259   0.325639  0.200415  0.293435  1.364478  t-SC-s  \n",
            "1077  0.158296  0.422121   0.321306  0.229193  0.355213  1.430825  t-SC-s  \n",
            "1078  0.196296  0.397676   0.335936  0.251317  0.365353  1.404031  t-SC-s  \n",
            "1079  0.187556  0.420347   0.335062  0.252995  0.365278  1.370999  t-SC-s  \n",
            "\n",
            "[1080 rows x 79 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Leemos los datos desde una URL externa\n",
        "data = pd.read_csv('http://www.uco.es/users/jmoyano/MiceProteinExpression_211018.csv')\n",
        "\n",
        "# Tras cargarlos, imprimimos para ver algunas de las columnas y sus valores\n",
        "print(data)\n",
        "\n",
        "# Imputar posibles valores perdidos con la media de la columna\n",
        "# Este proceso formaria parte del pre-procesado de datos;\n",
        "#   realizado simplemente para poder trabajar con ellos, sin entrar en más detalle\n",
        "from sklearn.impute import SimpleImputer\n",
        "for column in data.columns:\n",
        "  if data[column].isnull().values.any():\n",
        "    data[[column]] = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(data[[column]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eeib6pAov7no"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información del dataset al completo\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1080 entries, 0 to 1079\n",
            "Data columns (total 79 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   MouseID          1080 non-null   object \n",
            " 1   DYRK1A_N         1080 non-null   float64\n",
            " 2   ITSN1_N          1080 non-null   float64\n",
            " 3   BDNF_N           1080 non-null   float64\n",
            " 4   NR1_N            1080 non-null   float64\n",
            " 5   NR2A_N           1080 non-null   float64\n",
            " 6   pAKT_N           1080 non-null   float64\n",
            " 7   pBRAF_N          1080 non-null   float64\n",
            " 8   pCAMKII_N        1080 non-null   float64\n",
            " 9   pCREB_N          1080 non-null   float64\n",
            " 10  pELK_N           1080 non-null   float64\n",
            " 11  pERK_N           1080 non-null   float64\n",
            " 12  pJNK_N           1080 non-null   float64\n",
            " 13  PKCA_N           1080 non-null   float64\n",
            " 14  pMEK_N           1080 non-null   float64\n",
            " 15  pNR1_N           1080 non-null   float64\n",
            " 16  pNR2A_N          1080 non-null   float64\n",
            " 17  pNR2B_N          1080 non-null   float64\n",
            " 18  pPKCAB_N         1080 non-null   float64\n",
            " 19  pRSK_N           1080 non-null   float64\n",
            " 20  AKT_N            1080 non-null   float64\n",
            " 21  BRAF_N           1080 non-null   float64\n",
            " 22  CAMKII_N         1080 non-null   float64\n",
            " 23  CREB_N           1080 non-null   float64\n",
            " 24  ELK_N            1080 non-null   float64\n",
            " 25  ERK_N            1080 non-null   float64\n",
            " 26  GSK3B_N          1080 non-null   float64\n",
            " 27  JNK_N            1080 non-null   float64\n",
            " 28  MEK_N            1080 non-null   float64\n",
            " 29  TRKA_N           1080 non-null   float64\n",
            " 30  RSK_N            1080 non-null   float64\n",
            " 31  APP_N            1080 non-null   float64\n",
            " 32  Bcatenin_N       1080 non-null   float64\n",
            " 33  SOD1_N           1080 non-null   float64\n",
            " 34  MTOR_N           1080 non-null   float64\n",
            " 35  P38_N            1080 non-null   float64\n",
            " 36  pMTOR_N          1080 non-null   float64\n",
            " 37  DSCR1_N          1080 non-null   float64\n",
            " 38  AMPKA_N          1080 non-null   float64\n",
            " 39  NR2B_N           1080 non-null   float64\n",
            " 40  pNUMB_N          1080 non-null   float64\n",
            " 41  RAPTOR_N         1080 non-null   float64\n",
            " 42  TIAM1_N          1080 non-null   float64\n",
            " 43  pP70S6_N         1080 non-null   float64\n",
            " 44  NUMB_N           1080 non-null   float64\n",
            " 45  P70S6_N          1080 non-null   float64\n",
            " 46  pGSK3B_N         1080 non-null   float64\n",
            " 47  pPKCG_N          1080 non-null   float64\n",
            " 48  CDK5_N           1080 non-null   float64\n",
            " 49  S6_N             1080 non-null   float64\n",
            " 50  ADARB1_N         1080 non-null   float64\n",
            " 51  AcetylH3K9_N     1080 non-null   float64\n",
            " 52  RRP1_N           1080 non-null   float64\n",
            " 53  BAX_N            1080 non-null   float64\n",
            " 54  ARC_N            1080 non-null   float64\n",
            " 55  ERBB4_N          1080 non-null   float64\n",
            " 56  nNOS_N           1080 non-null   float64\n",
            " 57  Tau_N            1080 non-null   float64\n",
            " 58  GFAP_N           1080 non-null   float64\n",
            " 59  GluR3_N          1080 non-null   float64\n",
            " 60  GluR4_N          1080 non-null   float64\n",
            " 61  IL1B_N           1080 non-null   float64\n",
            " 62  P3525_N          1080 non-null   float64\n",
            " 63  pCASP9_N         1080 non-null   float64\n",
            " 64  PSD95_N          1080 non-null   float64\n",
            " 65  SNCA_N           1080 non-null   float64\n",
            " 66  Ubiquitin_N      1080 non-null   float64\n",
            " 67  pGSK3B_Tyr216_N  1080 non-null   float64\n",
            " 68  SHH_N            1080 non-null   float64\n",
            " 69  BAD_N            1080 non-null   float64\n",
            " 70  BCL2_N           1080 non-null   float64\n",
            " 71  pS6_N            1080 non-null   float64\n",
            " 72  pCFOS_N          1080 non-null   float64\n",
            " 73  SYP_N            1080 non-null   float64\n",
            " 74  H3AcK18_N        1080 non-null   float64\n",
            " 75  EGR1_N           1080 non-null   float64\n",
            " 76  H3MeK4_N         1080 non-null   float64\n",
            " 77  CaNA_N           1080 non-null   float64\n",
            " 78  class            1080 non-null   object \n",
            "dtypes: float64(77), object(2)\n",
            "memory usage: 666.7+ KB\n",
            "None\n",
            "---\n",
            "\n",
            "Columnas: 79\n",
            "Filas: 1080\n",
            "Clases: ['c-CS-m' 'c-SC-m' 'c-CS-s' 'c-SC-s' 't-CS-m' 't-SC-m' 't-CS-s' 't-SC-s']\n",
            "c-CS-m    150\n",
            "c-SC-m    150\n",
            "c-CS-s    135\n",
            "c-SC-s    135\n",
            "t-CS-m    135\n",
            "t-SC-m    135\n",
            "t-SC-s    135\n",
            "t-CS-s    105\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Vamos a conocer ciertas características de nuestros datos\n",
        "\n",
        "# Imprimimos información del conjunto de datos al completo\n",
        "print('Información del dataset al completo')\n",
        "print(data.info())\n",
        "print('---\\n')\n",
        "\n",
        "# Número de columnas\n",
        "print('Columnas: ' + str(len(data.columns)))\n",
        "\n",
        "# Número de filas\n",
        "print('Filas: ' + str(len(data)))\n",
        "\n",
        "# Almacenar e imprimir los distintos valores de las clases\n",
        "clases = data['class'].unique()\n",
        "print('Clases: ' + str(clases))\n",
        "\n",
        "# Apariciones de cada clase\n",
        "print(data['class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qi8VllZzlBv"
      },
      "source": [
        "Una vez visualizadas las características de nuestro conjunto de datos, podemos observar ciertas características:\n",
        "\n",
        "*   Contiene una primera columna de ID\n",
        "*   Contiene atributos unicamente de tipo numérico\n",
        "*   La última columna contiene el atributo de clase\n",
        "*   Tenemos 8 clases distintas, bastante balanceadas. La más frecuente aparece en 150 patrones, y la menos en 105.\n",
        "\n",
        "Por tanto, deberíamos hacer, al menos, el siguiente pre-procesado de los datos:\n",
        "*   Eliminar la columna ID\n",
        "*   Separar los atributos de entrada y la clase en variables distintas\n",
        "\n",
        "Como se indica, en casos en que sea necesario, puede filtrar columnas de los datos para que las ejecuciones sean menos costosas (vea comentario en el código). No es necesario realizar dicha selección de variables, simplemente en caso que el alumno considere para tener ejecuciones más rápidas.\n",
        "\n",
        "Además, vamos a realizar un particionado de los datos para su posterior utilización. En este caso, vamos a realizar una partición de los datos aleatoriamente en hold-out, utilizando un 70% de los datos para entrenamiento y el 30% restante para test. Esas particiones se usarán en adelante para todos los métodos, para así obtener unos resultados consistentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tvdNt0fYziMU"
      },
      "outputs": [],
      "source": [
        "# Atributos de entrada en X (eliminamos ID y clase)\n",
        "X = data.drop(columns=['MouseID', 'class'])\n",
        "\n",
        "# El proceso de predicción de kNN puede ser costoso.\n",
        "# Si el estudiante lo considera, puede reducir el número de atributos del conjunto \n",
        "#   de datos como se indica en las siguientes líneas. En dichas líneas se están \n",
        "#   manteniendo las n primeras columnas de los datos.\n",
        "# Los resultados obviamente cambiarán dependiendo del número de atributos que mantengamos\n",
        "#   en el conjunto de datos (por lo general, al reducir el número de atributos\n",
        "#   obtendremos peores resultados).\n",
        "# Sin embargo, se espera que el código funcione igualmente (aunque más lento) para\n",
        "#   el conjunto de datos completo, y que las respuestas a las distintas preguntas\n",
        "#   sea consistente con los resultados obtenidos con las n primeras columnas que\n",
        "#   se mantengan.\n",
        "\n",
        "# n = 30\n",
        "# X = X[X.columns[0:n]]\n",
        "\n",
        "# Atributo de clase en y\n",
        "y = data['class']\n",
        "\n",
        "# Particionado de los datos en entrenamiento y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlPHHIEXyfXv"
      },
      "source": [
        "Por último, vamos a realizar un escalado de los datos, de modo que se encuentren en el rango [0, 1].\n",
        "A partir de ahora, vamos a considerar las particiones de entrenamiento y test que ya tenemos, por lo que la función de escalado la \"entrenaremos\" utilizando la partición de entrenamiento, y posteriormente la aplicaremos a ambos subconjuntos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "He8PJjh6rWGe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
            "271   0.054181  0.106474  0.471912  0.517374  0.367249  0.411274  0.516004   \n",
            "140   0.199776  0.258534  0.618210  0.475502  0.419707  0.363898  0.480685   \n",
            "649   0.268964  0.337061  0.618420  0.521633  0.432118  0.351904  0.428993   \n",
            "194   0.003612  0.015133  0.113809  0.147046  0.143260  0.258068  0.359064   \n",
            "367   0.660648  0.613879  0.501000  0.460337  0.386189  0.325288  0.452642   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1033  0.052823  0.059351  0.553245  0.296299  0.150065  0.442981  0.524046   \n",
            "763   0.080165  0.145415  0.608576  0.464178  0.307266  0.531871  0.653196   \n",
            "835   0.096514  0.136877  0.299511  0.256445  0.250052  0.328984  0.411487   \n",
            "559   0.033625  0.049020  0.513055  0.442781  0.447294  0.363979  0.388182   \n",
            "684   0.105776  0.133157  0.468060  0.368817  0.286204  0.352954  0.480359   \n",
            "\n",
            "      pCAMKII_N   pCREB_N    pELK_N  ...     SHH_N     BAD_N    BCL2_N  \\\n",
            "271    0.647950  0.706371  0.099442  ...  0.175737  0.179736  0.300101   \n",
            "140    0.591941  0.590116  0.170364  ...  0.401174  0.233887  0.095369   \n",
            "649    0.191486  0.557332  0.238356  ...  0.115610  0.207047  0.107139   \n",
            "194    0.391440  0.178757  0.056364  ...  0.333291  0.380600  0.208745   \n",
            "367    0.227278  0.429311  0.471238  ...  0.144964  0.364839  0.285603   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "1033   0.403250  0.383261  0.104721  ...  0.243959  0.578975  0.481366   \n",
            "763    0.501159  0.703035  0.133870  ...  0.716733  0.744979  0.517995   \n",
            "835    0.467707  0.407623  0.114147  ...  0.488930  0.338812  0.301379   \n",
            "559    0.674923  0.422137  0.033086  ...  0.440492  0.322312  0.216593   \n",
            "684    0.343695  0.489882  0.086582  ...  0.367111  0.478437  0.272029   \n",
            "\n",
            "         pS6_N   pCFOS_N     SYP_N  H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N  \n",
            "271   0.679811  0.094225  0.367161   0.099136  0.299844  0.332097  0.307180  \n",
            "140   0.612385  0.037064  0.417229   0.086876  0.121514  0.164131  0.612072  \n",
            "649   0.449033  0.082272  0.363577   0.035056  0.056123  0.098995  0.920832  \n",
            "194   0.569641  0.409382  0.173775   0.167445  0.384261  0.236530  0.168971  \n",
            "367   0.376826  0.163701  0.409615   0.224755  0.280731  0.332097  0.897685  \n",
            "...        ...       ...       ...        ...       ...       ...       ...  \n",
            "1033  0.339043  0.514431  0.140243   0.395225  0.299844  0.493974  0.085524  \n",
            "763   0.920355  0.483382  0.447651   0.467026  0.630835  0.679455  0.366652  \n",
            "835   0.754809  0.317815  0.220154   0.178190  0.372132  0.231556  0.225646  \n",
            "559   0.672424  0.213819  0.607864   0.307903  0.265595  0.260229  0.436641  \n",
            "684   0.364447  0.302184  0.357031   0.175292  0.312041  0.361481  0.840648  \n",
            "\n",
            "[756 rows x 77 columns]\n",
            "DYRK1A_N     0.0\n",
            "ITSN1_N      0.0\n",
            "BDNF_N       0.0\n",
            "NR1_N        0.0\n",
            "NR2A_N       0.0\n",
            "            ... \n",
            "SYP_N        0.0\n",
            "H3AcK18_N    0.0\n",
            "EGR1_N       0.0\n",
            "H3MeK4_N     0.0\n",
            "CaNA_N       0.0\n",
            "Length: 77, dtype: float64\n",
            "DYRK1A_N     1.0\n",
            "ITSN1_N      1.0\n",
            "BDNF_N       1.0\n",
            "NR1_N        1.0\n",
            "NR2A_N       1.0\n",
            "            ... \n",
            "SYP_N        1.0\n",
            "H3AcK18_N    1.0\n",
            "EGR1_N       1.0\n",
            "H3MeK4_N     1.0\n",
            "CaNA_N       1.0\n",
            "Length: 77, dtype: float64\n",
            "      DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
            "904   0.177604  0.231459  0.333803  0.408538  0.357655  0.231969  0.305415   \n",
            "934   0.197323  0.220940  0.453969  0.399323  0.334077  0.311596  0.386124   \n",
            "692   0.259689  0.334698  0.526530  0.517287  0.357878  0.335307  0.415653   \n",
            "535   0.026217  0.052064  0.186187  0.274320  0.189682  0.327328  0.360947   \n",
            "678   0.128049  0.172112  0.606456  0.564885  0.451376  0.360009  0.467387   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1030  0.086904  0.091610  0.502349  0.422836  0.270416  0.396971  0.641818   \n",
            "38    0.157955  0.217986  0.651578  0.550876  0.630102  0.385420  0.476236   \n",
            "1044  0.085491  0.138264  0.746941  0.499785  0.412796  0.543446  0.575341   \n",
            "803   0.073727  0.136529  0.300195  0.441923  0.345222  0.450553  0.624152   \n",
            "330   0.137968  0.169178  0.550026  0.473620  0.405742  0.212616  0.265735   \n",
            "\n",
            "      pCAMKII_N   pCREB_N    pELK_N  ...     SHH_N     BAD_N    BCL2_N  \\\n",
            "904    0.112059  0.398424  0.158837  ...  0.210044  0.228962  0.155522   \n",
            "934    0.198730  0.495272  0.124371  ...  0.383527  0.381166  0.217750   \n",
            "692    0.707485  0.633786  0.169952  ...  0.337469  0.324982  0.166291   \n",
            "535    0.187820  0.300181  0.060781  ...  0.461189  0.420727  0.349335   \n",
            "678    0.451214  0.549998  0.112834  ...  0.267606  0.292905  0.139449   \n",
            "...         ...       ...       ...  ...       ...       ...       ...   \n",
            "1030   0.574093  0.474067  0.126630  ...  0.282936  0.705924  0.522879   \n",
            "38     0.202414  0.428034  0.213879  ...  0.306345  0.408952  0.307582   \n",
            "1044   0.817792  0.712041  0.130257  ...  0.454174  0.578631  0.271444   \n",
            "803    0.582638  0.643455  0.120963  ...  0.202346  0.251909  0.209772   \n",
            "330    0.243069  0.435356  0.113856  ...  0.401611  0.391310  0.300101   \n",
            "\n",
            "         pS6_N   pCFOS_N     SYP_N  H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N  \n",
            "904   0.538218  0.226837  0.285213   0.041829  0.154619  0.090717  0.570269  \n",
            "934   0.542597  0.184401  0.590711   0.269715  0.253038  0.330555  0.787959  \n",
            "692   0.466733  0.208426  0.378984   0.251157  0.139244  0.226584  0.690555  \n",
            "535   0.736442  0.483702  0.391417   0.201101  0.324588  0.510154  0.559551  \n",
            "678   0.499743  0.163036  0.506428   0.085572  0.167156  0.152171  0.886380  \n",
            "...        ...       ...       ...        ...       ...       ...       ...  \n",
            "1030  0.460031  0.423676  0.203510   0.462363  0.299844  0.465781  0.104889  \n",
            "38    0.659835  0.207588  0.515441   0.159448  0.325994  0.332097  0.623496  \n",
            "1044  0.697604  0.158347  0.469590   0.229312  0.245401  0.372648  0.359508  \n",
            "803   0.672445  0.090204  0.272518   0.224755  0.182256  0.332097  0.303853  \n",
            "330   0.573595  0.164720  0.388698   0.093625  0.299844  0.122371  0.656255  \n",
            "\n",
            "[324 rows x 77 columns]\n",
            "DYRK1A_N    -0.007649\n",
            "ITSN1_N     -0.008008\n",
            "BDNF_N      -0.260654\n",
            "NR1_N        0.029874\n",
            "NR2A_N       0.018175\n",
            "               ...   \n",
            "SYP_N        0.047481\n",
            "H3AcK18_N    0.006680\n",
            "EGR1_N      -0.006142\n",
            "H3MeK4_N     0.010066\n",
            "CaNA_N      -0.027623\n",
            "Length: 77, dtype: float64\n",
            "DYRK1A_N     0.923263\n",
            "ITSN1_N      0.972788\n",
            "BDNF_N       0.893743\n",
            "NR1_N        0.827008\n",
            "NR2A_N       0.784908\n",
            "               ...   \n",
            "SYP_N        0.753854\n",
            "H3AcK18_N    0.760449\n",
            "EGR1_N       0.907311\n",
            "H3MeK4_N     0.942065\n",
            "CaNA_N       1.009567\n",
            "Length: 77, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Ignoramos warning\n",
        "import warnings\n",
        "from pandas.core.common import SettingWithCopyWarning\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
        "\n",
        "# Escalamos los atributos al rango [0, 1]; unicamente columnas numéricas (float o int)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "for column in X_train.columns:\n",
        "  if 'float' in str(X_train.dtypes[column]) or 'int' in str(X_train.dtypes[column]):\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train[[column]] = scaler.fit_transform(X_train[[column]])\n",
        "    X_test[[column]] = scaler.transform(X_test[[column]])\n",
        "\n",
        "# Imprimimos dataset al completo, y valores minimo y maximo de cada columna, para comprobar que se realizó correctamente\n",
        "# En entrenamiento, los valores mínimos deben ser 0 y los máximos 1 en todas las variables\n",
        "print(X_train)\n",
        "print(X_train.min(axis=0))\n",
        "print(X_train.max(axis=0))\n",
        "\n",
        "# En test, los valores mínimo y máximo no deben ser estrictamente 0 y 1 respectivamente\n",
        "#   pero se les espera cercanos a dichos valores.\n",
        "print(X_test)\n",
        "print(X_test.min(axis=0))\n",
        "print(X_test.max(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSzFWxAh94Py"
      },
      "source": [
        "## 1. Implementar función de distancia (1 punto)\n",
        "\n",
        "Dado que kNN es un método basado en vecindad, es decir, en aquellos patrones más cercanos, tendremos que definir una función, o funciones de distancia entre patrones para poder determinar su cercanía. \n",
        "**Nota:** Las funciones implementadas a lo largo del notebook tienen que funcionar no solo para este conjunto de datos, sino para cualquiera que contenga atributos reales y categóricos.\n",
        "\n",
        "A continuación, se incluye una celda de código, donde debe definir, al menos, la siguiente función:\n",
        "\n",
        "*   ``distancia(A, B, p)``: Esta función debe calcular la distancia entre dos patrones ``A`` y ``B`` (basándose en la [distancia de Minkowski](https://es.hrvwiki.net/wiki/Minkowski_distance), que es una generalización de otras distancias). La función devolverá un número real indicando la distancia entre ambos patrones. Más abajo se incluye la ecuación para calcular la distancia entre ``A`` y ``B``, dado el valor de ``p``. Dependiendo del valor de ``p``, la función de distancia será distinta:\n",
        "  *   p=1: Equivale a la [distancia de Manhattan](https://es.wikipedia.org/wiki/Geometr%C3%ADa_del_taxista)\n",
        "  *   p=2: Equivale a la [distancia Euclídea](https://es.wikipedia.org/wiki/Distancia_euclidiana)\n",
        "  *   ...\n",
        "\n",
        "$$distancia(A, B, p) = \\sqrt[p]{\\sum_{i=1}^{n}{\\left | A_i - B_i\\right | ^ p}}$$\n",
        "\n",
        "Al calcular la distancia, tendrá que tener en cuenta que si ambos valores son valores categóricos, la diferencia entre ellos será 0 si coinciden, y 1 en caso contrario. En caso de ser valores numéricos, la diferencia es el valor absoluto de la resta entre ambos valores.\n",
        "\n",
        "Nótese que tanto en la siguiente celda como en el resto del notebook, debe(n) existir la(s) funcion(es) requerida(s), pero se pueden implementar otras funciones auxiliares si se considera necesario sin ningún problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p22Uz8ZpE6ei"
      },
      "outputs": [],
      "source": [
        "# En esta celda, implemente la función para calcular la distancia entre dos patrones. \n",
        "# Respete la declaración de la cabecera de la función. Si lo considera necesario, \n",
        "#   puede añadir nuevos parámetros a la función, siempre que tengan valor por defecto.\n",
        "\n",
        "def distancia(A, B, p=2):\n",
        "  '''\n",
        "  Calcula la distancia con p-norma entre dos patrones A y B.\n",
        "  Válida para patrones que contengan atributos tanto numéricos como categóricos\n",
        "\n",
        "  :param A: Lista con valores para todos los atributos del patrón A\n",
        "  :param B: Lista con valores para todos los atributos del patrón B\n",
        "  :param p: Valor de la norma para el cálculo de distancia. Por defecto, p=2, es decir, calcula distancia euclídea\n",
        "   \n",
        "  :return: Valor numérico con la distancia entre ambos patrones\n",
        "  '''\n",
        "  ###\n",
        "  # COMPLETAR AQUI\n",
        "  ###\n",
        "\n",
        "  # TODO: Arreglar\n",
        "  distances = []\n",
        "\n",
        "  if len(A) != len(B):\n",
        "    return \"Error. La longitud de las listas no son iguales\"\n",
        "  \n",
        "  for i in range(0, len(A)):\n",
        "    \n",
        "    if type(A[i]) != type(B[i]):\n",
        "      return \"Error. El tipo de los parámetros A y B no coinciden\"\n",
        "\n",
        "    # Caso valor categórico\n",
        "    if isinstance(A[i], str) and isinstance(B[i], str):    \n",
        "\n",
        "        if A[i] == B[i]:\n",
        "          distances.append(0)\n",
        "\n",
        "        else:\n",
        "          distances.append(1)\n",
        "\n",
        "    # Caso valor numerico\n",
        "    else:\n",
        "\n",
        "      dis = np.power(np.abs(A[i] - B[i]), p)\n",
        "\n",
        "      distances.append(dis)\n",
        "\n",
        "  summatory = np.array(distances).sum()\n",
        "\n",
        "  return np.power(summatory, 1/p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sV4fz438DFX6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5000000000000001\n",
            "1.0488088481701516\n",
            "1.2222443459182537\n"
          ]
        }
      ],
      "source": [
        "# En esta celda, podrá probar si su función de distancia funciona correctamente.\n",
        "\n",
        "# Esta distancia debería ser 0.5\n",
        "print(distancia([0.8, 0.1, 0.45, 0.9], [0.7, 0.4, 0.45, 0.8], p=1))\n",
        "\n",
        "# Esta distancia debería ser 1.0488 (redondeando)\n",
        "print(distancia([0.8, 0.1, 0.45, 'A', 'b'], [0.7, 0.4, 0.45, 'A', 'c'], p=2))\n",
        "\n",
        "# Probar que funciona con dos patrones de los datos\n",
        "print(distancia(X_train.iloc[0], X_train.iloc[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7FAAJlXGHcO"
      },
      "source": [
        "## 2. Implementar kNN básico (2 puntos)\n",
        "\n",
        "Una vez tenemos implementada nuestra función de distancia, podemos implementar nuestra primera versión del método kNN. En este caso, se busca implementar el método básico, donde la predicción se produce en base a los k vecinos más cercanos, teniendo todos ellos el mismo peso en la predicción. Para cada patrón de *test*, el método ha de buscar los k vecinos más cercanos en los patrones de entrenamiento, y utilizar las clases asociadas a dichos vecinos para generar su salida.\n",
        "\n",
        "Sin embargo, se pretende que el método no devuelva una clase predicha, sino una probabilidad de pertenencia a cada clase. La probabilidad de pertenencia se calculará como el ratio de vecinos más cercanos pertenenciendo a cada clase de entre el total de vecinos. \n",
        "Como ejemplo, si estamos utilizando k=3, y hay 1 vecino de la clase A, 2 vecinos de la clase B, y 0 vecinos de la clase C, la salida debe ser una lista tal como: ``[0.333, 0.667, 0]``.\n",
        "\n",
        "En las siguiente celda encontrará la definición de la función ``kNN`` a completar. La función debe recibir varios parámetros:\n",
        "*   ``X_train``: patrones de entrenamiento utilizados para clasificar un nuevo patrón. Los vecinos de un patrón dado se buscarán en este conjunto. \n",
        "*   ``y_train``: clase asociada a cada uno de los patrones del conjunto anterior.\n",
        "*   ``X_test``: patrones de validación o test para los que queremos predecir su probabilidad de pertenencia a cada clase.\n",
        "*   ``k``: número de vecinos más cercanos a considerar en la clasificación. Por defecto debe utilizar ``k=1``.\n",
        "*   ``p``: valor de la norma para la función de distancia. Por defecto, ``p=2`` (distancia Euclídea).\n",
        "*   ``clases``: lista con los nombres de las distintas clases en el conjunto de datos. Si no se proporciona, se obtiene del conjunto de entrenamiento.\n",
        "\n",
        "Dado que para cada patrón el método debe devolver una lista de probabilidades (una por cada clase), la salida de la función será una lista de listas, una por cada instancia de test. Es decir, la salida debe seguir una estructura como la siguiente (considerando 8 clases distintas):\n",
        "\n",
        "``\n",
        "[[0.2, 0.0, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0], \n",
        "[0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4, 0.0], \n",
        "..., \n",
        "[0.2, 0.0, 0.4, 0.0, 0.2, 0.0, 0.0, 0.2]]\n",
        "``\n",
        "\n",
        "Si lo considera necesario, puede añadir más funciones auxiliares en la siguiente celda. También se considera que se utilizará la función ``distancia`` implementada anteriormente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HVV_5SHTIA_5"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def calculate_probabilities(counter, classes, k):\n",
        "  \"\"\"Método que calcula la probabilidad de pertenecia a cada una de las clases\n",
        "\n",
        "  Args:\n",
        "      counter (Counter): Objeto de tipo Counter que contiene el número de veces que se repite cada clase\n",
        "      classes (array): Contiene el tipo de clases que hay\n",
        "      k (int): K vecinos\n",
        "\n",
        "  Returns:\n",
        "      list: Probabilidades de pertenencia a cada clase para el patrón dado\n",
        "  \"\"\"\n",
        "\n",
        "  probs = []\n",
        "\n",
        "  for cl in classes:\n",
        "\n",
        "    probs.append(counter[cl]/k)\n",
        "\n",
        "  return probs\n",
        "\n",
        "def knn(X_train, y_train, X_test, k=1, p=2, clases=[]):\n",
        "  '''\n",
        "  Utiliza el método de los k vecinos para, a partir de los datos de entrenamiento, \n",
        "  devolver la probabilidad de pertenencia a cada clase para cada uno de los patrones\n",
        "  de test.\n",
        "\n",
        "  :param X_train: Conjunto de datos de entrenamiento. Se utiliza para buscar los k vecinos más cercanos a uno dado.\n",
        "  :param y_train: Clase asociada a cada uno de los patrones de entrenamiento. Necesario para generar probabilidades.\n",
        "  :param X_test: Conjunto de datos de test. Se pretende obtener la probabilidad de pertenencia a cada clase para cada uno de sus patrones.\n",
        "  :param k: Número de vecinos más cercanos. Por defecto, k=1, es decir, únicamente utiliza el vecino más cercano.\n",
        "  :param p: Valor de la norma para el cálculo de distancia. Por defecto, p=2, es decir, calcula distancia euclídea.\n",
        "  :param clases: Distintos valores para la variable de clase. Las probabilidades calculadas seguirán el orden indicado en esta lista.\n",
        "   \n",
        "  :return: Lista de listas con las probabilidades de pertenencia de cada patrón de test a cada clase. Además, si no se le pasó el parámetro clases, devuelve los valores de clase.\n",
        "  '''\n",
        "\n",
        "  # Si no se proporcionan los valores para la clase \n",
        "  return_classes = False # No modificar posteriormente en el código implementado\n",
        "  if len(clases) <= 0:\n",
        "    return_classes = True\n",
        "    clases = y_train.unique()\n",
        "\n",
        "  # Lista con probabilidades para cada patrón. Cada elemento de la lista será otra lista.\n",
        "  probabilities = []\n",
        "\n",
        "  ###\n",
        "  # COMPLETAR AQUI\n",
        "  ###\n",
        "\n",
        "  for _, test_row in X_test.iterrows():\n",
        "\n",
        "    distances = []\n",
        "\n",
        "    for _, train_row in X_train.iterrows():\n",
        "\n",
        "      distances.append(distancia(test_row, train_row))\n",
        "\n",
        "    df_distances = pd.DataFrame(data=distances, index = X_train.index, columns = [\"dist\"])\n",
        "    \n",
        "    sorted_distances = df_distances.sort_values(by=[\"dist\"], axis = 0)\n",
        "\n",
        "    k_distances = sorted_distances[:k]\n",
        "\n",
        "    counter = Counter(y_train[k_distances.index])\n",
        "\n",
        "    probabilities.append(calculate_probabilities(counter, clases, k))\n",
        "    \n",
        "  # Debería dejar de implementar aquí; se incluyen los return de la función\n",
        "  if return_classes:\n",
        "    return probabilities, clases\n",
        "  else:\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "# ### BORRAR ESTO\n",
        "# # Valores de clases\n",
        "# clases = y.unique()\n",
        "\n",
        "# # Evaluar knn básico \n",
        "# # COMPLETAR los ... con valores de correspondientes\n",
        "# knn_proba = knn(X_train, y_train, X_test, k=3, p=1, clases=clases)\n",
        "# Para cada array en y_proba, obtener la clase predicha\n",
        "# y_pred = []\n",
        "\n",
        "# y_pred = class_from_pred(knn_proba, clases, seed=0)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw18N2V_zmGA"
      },
      "source": [
        "Posteriormente, se incluye una función que será útil en el futuro. Dado un array con las probabilidades de pertenencia a cada clase para un patrón concreto, esta función se puede utilizar para devolver la clase predicha por el método, es decir, aquella con un mayor valor de probabilidad. La función recibe una lista con las probabilidades y otra con los nombres de cada una de las clases en el mismo orden que se tienen en el array de probabilidades.\n",
        "\n",
        "Basándonos en el ejemplo de antes, si la función recibe el array ``[0.333, 0.667, 0]`` y el array ``['A', 'B', 'C']``, debe devolver 'B' como clase predicha.\n",
        "\n",
        "Además, en caso de empate, la función escoge una clase aleatoriamente de entre aquellas con misma probabilidad. Así, nos aseguramos de que el método puede dar una salida en todos los casos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mto58x_w1CQe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def clase_max_prob(probabilidades, clases, seed=None):\n",
        "  '''\n",
        "  Devuelve la clase predicha para un patrón a partir del vector de probabilidades asociado a cada clase.\n",
        "  En caso de empate, devuelve una clase aleatoriamente de entre las que tenían\n",
        "    el mayor valor de probabilidad.\n",
        "\n",
        "  :param probabilidades: Lista con los valores de probabilidad de pertenencia a cada clase. Deben presentarse en el mismo orden de clases que el parámetro clases.\n",
        "  :param clases: Distintos valores para la variable de clase. Útil para obtener la clase predicha a partir de las probabilidades.\n",
        "  :param seed: Semilla para números aleatorios. Si es None (por defecto), no se asigna ninguna semilla dentro de la función.\n",
        "   \n",
        "  :return: Clase con vayor malor de probabilidad. Será un valor de la lista clases.\n",
        "  '''\n",
        "  # Asignar semilla de números aleatorios si es necesario\n",
        "  if seed is not None:\n",
        "    np.random.seed(seed)\n",
        "  \n",
        "  # Buscar mayor probabilidad \n",
        "  max_prob = max(probabilidades)\n",
        "\n",
        "  # Buscar indice(s) de las celdas con mayor probabilidad\n",
        "  indices = [index for index, p in enumerate(probabilidades) if p == max_prob]\n",
        "\n",
        "  # Si existen varias probabilidades que coinciden en el valor mayor, escoger una aleatoria\n",
        "  if len(indices) > 1:\n",
        "    clase = clases[np.random.choice(indices)]\n",
        "  else:\n",
        "    clase = clases[indices[0]]\n",
        "\n",
        "  # Devolver clase correspondiente con la mayor probabilidad\n",
        "  return clase\n",
        "\n",
        "\n",
        "def class_from_pred(probabilities, clases, seed=0):\n",
        "  '''\n",
        "  Devuelve una lista con las clases predichas, dada una lista de listas con las probabilidades para cada clase.\n",
        "  Similar a clase_max_prob, pero recibe las probabilidades de todo el conjunto de test/validacion\n",
        "  '''\n",
        "  pred = []\n",
        "  for pr in probabilities:\n",
        "    pred.append(clase_max_prob(pr, clases, seed))\n",
        "\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7344x4uilqu3"
      },
      "source": [
        "## 3. Implementar kNN con pesos (1 punto)\n",
        "\n",
        "Posteriormente, se busca que se implemente el método kNN donde los k patrones más cercanos no tienen el mismo peso en la decisión final, sino que su peso es inversamente proporcional al cuadrado de la distancia con el patrón de test (ver sección *Función de combinación* en la lectura obligatoria de la lección 1 de la semana 4).\n",
        "\n",
        "En este caso, la probabilidad de salida para un patrón se calcularía en dos pasos:\n",
        "1.   Calcular *peso* o *verosimilitud* de pertenencia del patrón $X$ cada clase $C_i$. Para ello, se seguirá la función siguiente, donde $Z$ sería cada vecino perteneciendo a la clase $C_i$, y $d(...)$ la función de distancia. Nótese que valores mayores de distancia entre el patrón $X$ y el vecino conllevan valores menores de *verosimilitud*; es decir, patrones más cercanos resultan en mayores valores de verosimilitud para dicha clase.\n",
        "$$v_{X, C_i} = \\sum_{Z \\in C_i}{\\frac{1}{d(X, Z)^2}}$$\n",
        "2.   La probabilidad de pertenencia a cada clase $C_i$ se calcula como la verosimilitud de pertenencia a dicha clase entre la suma de todas las verosimilitudes para un patrón dado.\n",
        "$$P(C_i|X) = \\frac{v_{X, C_i}}{\\sum_{j=1}^{\\textrm{nClases}}{v_{X, C_j}}}$$\n",
        "\n",
        "Los parámetros y salida del nuevo método ``knn_pesos`` seguirá la misma estructura que el método anterior. La diferencia principal es cómo calcular las probabilidades de pertenencia a la clase.\n",
        "\n",
        "En la siguiente celda contiene el código a completar en este apartado. Si lo considera oportuno, puede crear las funciones auxiliares que necesite y utilizar cualquier función creada con anterioridad. Puede apoyarse en gran medida en el código implementado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FkJ7bb46pE-T"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def calculate_probabilities_pesos(df_dis_class, classes):\n",
        "  probabilities = []\n",
        "\n",
        "  # Calculamos las verosimilitudes del patrón a todas las clases\n",
        "  verosimilies = {}\n",
        "  for cl in classes:\n",
        "\n",
        "    k_distances_cl = np.array(df_dis_class[df_dis_class[\"class\"] == cl][\"dist\"])\n",
        "\n",
        "    if len(k_distances_cl) == 0:\n",
        "      verosimilies[cl] = 0\n",
        "    else:\n",
        "\n",
        "      summ = 0\n",
        "\n",
        "      for dis in k_distances_cl:\n",
        "\n",
        "        summ += 1/dis**2\n",
        "\n",
        "      verosimilies[cl] = summ\n",
        "    \n",
        "  # Calculamos la probabilidad de pertenencia del patrón a todas las clases\n",
        "  summatory_ver = np.sum(list(verosimilies.values()))\n",
        "\n",
        "  for cl in classes:\n",
        "\n",
        "    probabilities.append(verosimilies[cl] / summatory_ver)\n",
        "\n",
        "  return probabilities\n",
        "\n",
        "def knn_pesos(X_train, y_train, X_test, k=1, p=2, clases=[]):\n",
        "  '''\n",
        "  Utiliza el método de los k vecinos para, a partir de los datos de entrenamiento, \n",
        "  devolver la probabilidad de pertenencia a cada clase para cada uno de los patrones\n",
        "  de test.\n",
        "\n",
        "  :param X_train: Conjunto de datos de entrenamiento. Se utiliza para buscar los k vecinos más cercanos a uno dado.\n",
        "  :param y_train: Clase asociada a cada uno de los patrones de entrenamiento. Necesario para generar probabilidades.\n",
        "  :param X_test: Conjunto de datos de test. Se pretende obtener la probabilidad de pertenencia a cada clase para cada uno de sus patrones.\n",
        "  :param k: Número de vecinos más cercanos. Por defecto, k=1, es decir, únicamente utiliza el vecino más cercano.\n",
        "  :param p: Valor de la norma para el cálculo de distancia. Por defecto, p=2, es decir, calcula distancia euclídea.\n",
        "  :param clases: Distintos valores para la variable de clase. Las probabilidades calculadas seguirán el orden indicado en esta lista.\n",
        "   \n",
        "  :return: Lista de listas con las probabilidades de pertenencia de cada patrón de test a cada clase. Además, si no se le pasó el parámetro clases, devuelve los valores de clase.\n",
        "  '''\n",
        "\n",
        "  ###\n",
        "  # COMPLETAR AQUI\n",
        "  ###\n",
        "  # Si no se proporcionan los valores para la clase \n",
        "  return_classes = False # No modificar posteriormente en el código implementado\n",
        "  if len(clases) <= 0:\n",
        "    return_classes = True\n",
        "    clases = y_train.unique()\n",
        "\n",
        "  # Lista con probabilidades para cada patrón. Cada elemento de la lista será otra lista.\n",
        "  probabilities = []\n",
        "\n",
        "  for _, test_row in X_test.iterrows():\n",
        "\n",
        "    distances = []\n",
        "\n",
        "    for _, train_row in X_train.iterrows():\n",
        "\n",
        "      distances.append(distancia(test_row, train_row))\n",
        "\n",
        "    df_distances = pd.DataFrame(data=distances, index = X_train.index, columns = [\"dist\"])\n",
        "    \n",
        "    sorted_distances = df_distances.sort_values(by=[\"dist\"], axis = 0)\n",
        "\n",
        "    k_distances = sorted_distances[:k]\n",
        "\n",
        "    class_k_distances = y_train[k_distances.index]\n",
        "\n",
        "    k_distances[\"class\"] = class_k_distances\n",
        "\n",
        "    probabilities.append(calculate_probabilities_pesos(k_distances, clases))\n",
        "    \n",
        "  # Debería dejar de implementar aquí; se incluyen los return de la función\n",
        "  if return_classes:\n",
        "    return probabilities, clases\n",
        "  else:\n",
        "    return probabilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezRBfdkvpaUd"
      },
      "source": [
        "## 4. Estudio de los parámetros (0.75 puntos)\n",
        "\n",
        "Teniendo implementados nuestros dos métodos, en este cuarto apartado vamos a hacer un estudio de los parámetros de ambos métodos.\n",
        "\n",
        "Dado que el proceso de selección de parámetros se realiza para escoger la mejor configuración a utilizar posteriormente en los datos de test, dicho estudio se ha de realizar utilizando **solo** los datos de entrenamiento, y nunca los de test.\n",
        "\n",
        "El objetivo de este cuarto apartado es que, tomando los datos de entrenamiento, se vuelva a hacer una partición de datos en entrenamiento y validación, de modo que se entrenen varios métodos utilizando distintos parámetros con los datos de entrenamiento, y se evalúen utilizando los de validación. Además, se espera que este proceso se realice varias veces con distintas particiones, para evitar sesgos por la elección de las particiones de entrenamiento/validación.\n",
        "\n",
        "Debe completar la función ``validate_knn`` donde, a partir de los datos de entrenamiento y validación generados internamente debe: 1) entrenar un modelo knn (clásico o con pesos, dependiendo del parámetro ``usar_pesos``) y obtener probabilidades predichas en validación; 2) obtener la clase predicha para cada instancia de validación; y 3) calcular ciertas métricas de evaluación. \n",
        "\n",
        "La función ``repeat_validation_knn`` se encuentra completamente implementada. Esta función realiza varias llamadas a la función ``validate_knn`` para estimar las métricas de evaluación en distintos escenarios de particiones de entrenamiento/validación. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k2cUYM35wQrl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "def validate_knn(X, y, k=1, p=2, usar_pesos=False, validation_size=0.33, random_state=0):\n",
        "  '''\n",
        "  Esta función realiza un particionado de los datos de manera interna entre entrenamiento y validación.\n",
        "  Utiliza la partición interna de entrenamiento para \"entrenar\" kNN y predice sobre los de test.\n",
        "  Devuelve el valor de varias métricas de evaluación sobre el conjunto de validación.\n",
        "  Dependiendo del parámetro usar_pesos, utilizará la versión clásica de kNN (False), o la que utiliza la distancia como peso para calcular la probabilidad (True)\n",
        "\n",
        "  :param X: Datos de entrada a utilizar.\n",
        "  :param y: Clase asociada a cada patrón de X.\n",
        "  :param k: Número de vecinos más cercanos. Por defecto, k=1, es decir, únicamente utiliza el vecino más cercano.\n",
        "  :param p: Valor de la norma para el cálculo de distancia. Por defecto, p=2, es decir, calcula distancia euclídea.\n",
        "  :param usar_pesos: Parámetro que indica si utilizar la versión clásica de kNN (False), o si los patrones más cercanos tienen más peso en la predicción (True). Por defecto, utiliza la versión clásica (False)\n",
        "  :param validation_size: Ratio de patrones que se utilizarán como partición de validación\n",
        "  :param random_state: Semilla aleatoria para generar las particiones de entrenamiento/validación.\n",
        "\n",
        "  :return: Lista con valores para distintas métricas de evaluación\n",
        "  '''\n",
        "  clases = y.unique()\n",
        "\n",
        "  # Particionar los datos en puro entrenamiento, y validación\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_size, random_state=random_state)\n",
        "\n",
        "  # Entrenar knn con datos de entrenamiento, y predecir sobre los de validación\n",
        "  \n",
        "  ###\n",
        "  # COMPLETAR AQUI\n",
        "  #   Se proporcionan como comentarios posibles partes de la función para que sirva de ayuda\n",
        "  #   Sin embargo, no es necesario seguir esas recomendaciones\n",
        "  ###\n",
        "\n",
        "  if usar_pesos:\n",
        "    y_proba = knn_pesos(X_train, y_train, X_val, k=k, p=p, clases=clases)\n",
        "  else:\n",
        "    y_proba = knn(X_train, y_train, X_val, k=k, p=p, clases=clases)\n",
        "\n",
        "  # Para cada array en y_proba, obtener la clase predicha\n",
        "  y_pred = []\n",
        "\n",
        "  y_pred = class_from_pred(y_proba, clases, seed=0)\n",
        "\n",
        "\n",
        "  # Debería dejar de implementar aquí\n",
        "  # Calcular métricas de evaluación\n",
        "  #   El estudiante puede incluir otras si lo considera oportuno, y modificar la función para que las devuelva\n",
        "  accuracy = accuracy_score(y_val, y_pred)\n",
        "  f1 = f1_score(y_val, y_pred, average='macro')\n",
        "  kappa = cohen_kappa_score(y_val, y_pred)\n",
        "\n",
        "  return accuracy, f1, kappa\n",
        "\n",
        "\n",
        "def repeat_validation_knn(X, y, k=1, p=2, usar_pesos=False, validation_size=0.33, iter=10, random_state=0, verbose=True):\n",
        "  '''\n",
        "  Esta función hace uso de la función validate_knn para repetir el proceso varias veces,\n",
        "    devolviendo el valor medio para cada una de las métricas.\n",
        "  De este modo, repitiendo el proceso varias veces con distintas particiones, se busca\n",
        "    reducir el sesgo producido por dicha elección de particiones de entrenamiento/validación. \n",
        "\n",
        "  :param X: Datos de entrada a utilizar.\n",
        "  :param y: Clase asociada a cada patrón de X.\n",
        "  :param k: Número de vecinos más cercanos. Por defecto, k=1, es decir, únicamente utiliza el vecino más cercano.\n",
        "  :param p: Valor de la norma para el cálculo de distancia. Por defecto, p=2, es decir, calcula distancia euclídea.\n",
        "  :param usar_pesos: Parámetro que indica si utilizar la versión clásica de kNN (False), o si los patrones más cercanos tienen más peso en la predicción (True). Por defecto, utiliza la versión clásica (False)\n",
        "  :param validation_size: Ratio de patrones que se utilizarán como partición de validación\n",
        "  :param iter: Número de iteraciones o repeticiones distintas, utilizando distintas particiones\n",
        "  :param random_state: Semilla aleatoria para generar las particiones de entrenamiento/validación.\n",
        "  :param verbose: Indica si muestra cierta información sobre el proceso de validación (iteraciones). Por defecto, True.\n",
        "\n",
        "  :return: Lista con valores para distintas métricas de evaluación\n",
        "  '''\n",
        "  avg_accuracy = 0 \n",
        "  avg_f1 = 0\n",
        "  avg_kappa = 0\n",
        "  for i in range(iter):\n",
        "    if verbose:\n",
        "      print('Iteracion ' + str(i+1) + ' de ' + str(iter))\n",
        "    accuracy, f1, kappa = validate_knn(X, y, k=k, p=p, usar_pesos= usar_pesos, validation_size=validation_size, random_state = ((random_state+i)*i))\n",
        "    avg_accuracy += accuracy\n",
        "    avg_f1 += f1\n",
        "    avg_kappa += kappa\n",
        "  \n",
        "  avg_accuracy = avg_accuracy / iter\n",
        "  avg_f1 = avg_f1 / iter\n",
        "  avg_kappa = avg_kappa / iter\n",
        "\n",
        "  return avg_accuracy, avg_f1, avg_kappa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCUv3pv65Qj6"
      },
      "source": [
        "En la siguiente celda, debe utilizar las funciones anteriores (``repeat_validation_knn``) para probar varias combinaciones de parámetros para ambos métodos de knn implementados, y determinar, razonadamente, cuál es la mejor combinación de parámetros en cada caso. Incluya el código necesario en la siguiente celda, y razone su respuesta al final de esta misma celda.\n",
        "\n",
        "Notas:\n",
        "*   Puede probar, por ejemplo, ``p=[1, 2]``, y ``k=[1, 3, 5, 9]``, para ambos métodos. Sin embargo, el estudiante puede escoger otras combinaciones si así lo desea.\n",
        "*   En cada caso, idealmente se realizarían 10 iteraciones (parámetro ``iter=10``). Sin embargo, si el proceso es muy costoso, podría reducirlo a 5 o 3 iteraciones unicamente.\n",
        "*   Todas las llamadas a la función ``repeat_validation_knn`` deben hacerse con el mismo valor para el parámetro ``random_state``, asegurándonos así una comparación justa sobre las mismas particiones.\n",
        "*   El ratio de instancias de validación queda a elección del usuario. Por lo general, suele ser un valor entre 0.1 y 0.33; también suele estar relacionado con el número de iteraciones (si se realizan 10 iteraciones podría dejarse en 0.1; si se realizan unicamente 3 iteraciones por ejemplo, podría fijarse a 0.33). Queda a elección del estudiante.\n",
        "\n",
        "¿Cuál es la mejor combinación de parámetros para cada modelo de knn (con y sin pesos), y por qué? ¿Qué conclusiones puede sacar a partir de los resultados obtenidos?\n",
        "\n",
        "**RESPUESTA**: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PqNCg0fE6w1i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN: k = 1 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 1 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 1 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 1 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 3 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 3 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 3 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 3 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 5 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 5 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 5 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 5 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 9 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN: k = 9 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 9 - p = 1\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n",
            "KNN Pesos: k = 9 - p = 2\n",
            "Iteracion 1 de 3\n",
            "Iteracion 2 de 3\n",
            "Iteracion 3 de 3\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "# COMPLETAR AQUI\n",
        "###\n",
        "\n",
        "# Incluya el código necesario, realizando llamadas a la función repeat_validation_knn\n",
        "#   para cumplir con lo propuesto en la celda anterior y determinar la mejor\n",
        "#   combinación de parámetros para cada método de knn\n",
        "\n",
        "knn_val_1 = {}\n",
        "knn_val_2 = {}\n",
        "knn_pesos_val_1 = {}\n",
        "knn_pesos_val_2 = {}\n",
        "\n",
        "for i in [1, 3, 5, 9]:\n",
        "    print(\"KNN: k = \" + str(i) + \" - \" + \"p = 1\")\n",
        "    knn_val_1[\"k_\" + str(i)] = [repeat_validation_knn(X, y, k=i, p=1, usar_pesos=False, validation_size=0.33, iter=3, random_state=0, verbose=True)]\n",
        "\n",
        "    print(\"KNN: k = \" + str(i) + \" - \" + \"p = 2\")\n",
        "    knn_val_2[\"k_\" + str(i)] = [repeat_validation_knn(X, y, k=i, p=2, usar_pesos=False, validation_size=0.33, iter=3, random_state=0, verbose=True)]\n",
        "\n",
        "    print(\"KNN Pesos: k = \" + str(i) + \" - \" + \"p = 1\")\n",
        "    knn_pesos_val_1[\"k_\" + str(i)] = [repeat_validation_knn(X, y, k=i, p=1, usar_pesos=True, validation_size=0.33, iter=3, random_state=0, verbose=True)]\n",
        "\n",
        "    print(\"KNN Pesos: k = \" + str(i) + \" - \" + \"p = 2\")\n",
        "    knn_pesos_val_2[\"k_\" + str(i)] = [repeat_validation_knn(X, y, k=i, p=2, usar_pesos=True, validation_size=0.33, iter=3, random_state=0, verbose=True)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN - K=1 - p=1 - it=3\n",
            "Acc: 0.9701213818860878\n",
            "F1: 0.9714058339779555\n",
            "Kappa: 0.9657707798960026\n",
            "kNN - K=3 - p=1 - it=3\n",
            "Acc: 0.9253034547152194\n",
            "F1: 0.9276727540444699\n",
            "Kappa: 0.9144859526283953\n",
            "kNN - K=5 - p=1 - it=3\n",
            "Acc: 0.8982259570494865\n",
            "F1: 0.9001110317667544\n",
            "Kappa: 0.8834692648502029\n",
            "kNN - K=9 - p=1 - it=3\n",
            "Acc: 0.8225957049486462\n",
            "F1: 0.8251682571345128\n",
            "Kappa: 0.796832636665326\n"
          ]
        }
      ],
      "source": [
        "for i in [1,3,5,9]:\n",
        "    print(\"kNN - K=\"+str(i)+\" - p=1 - it=3\")\n",
        "    print(\"Acc: \" + str(knn_val_1[\"k_\" + str(i)][0][0]))\n",
        "    print(\"F1: \" + str(knn_val_1[\"k_\" + str(i)][0][1]))\n",
        "    print(\"Kappa: \" + str(knn_val_1[\"k_\" + str(i)][0][2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN - K=1 - p=2 - it=3\n",
            "Acc: 0.9701213818860878\n",
            "F1: 0.9714058339779555\n",
            "Kappa: 0.9657707798960026\n",
            "kNN - K=3 - p=2 - it=3\n",
            "Acc: 0.9253034547152194\n",
            "F1: 0.9276727540444699\n",
            "Kappa: 0.9144859526283953\n",
            "kNN - K=5 - p=2 - it=3\n",
            "Acc: 0.8982259570494865\n",
            "F1: 0.9001110317667544\n",
            "Kappa: 0.8834692648502029\n",
            "kNN - K=9 - p=2 - it=3\n",
            "Acc: 0.8225957049486462\n",
            "F1: 0.8251682571345128\n",
            "Kappa: 0.796832636665326\n"
          ]
        }
      ],
      "source": [
        "for i in [1,3,5,9]:\n",
        "    print(\"kNN - K=\"+str(i)+\" - p=2 - it=3\")\n",
        "    print(\"Acc: \" + str(knn_val_2[\"k_\" + str(i)][0][0]))\n",
        "    print(\"F1: \" + str(knn_val_2[\"k_\" + str(i)][0][1]))\n",
        "    print(\"Kappa: \" + str(knn_val_2[\"k_\" + str(i)][0][2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN Pesos - K=1 - p=1 - it=3\n",
            "Acc: 0.9701213818860878\n",
            "F1: 0.9714058339779555\n",
            "Kappa: 0.9657707798960026\n",
            "kNN Pesos - K=3 - p=1 - it=3\n",
            "Acc: 0.96171802054155\n",
            "F1: 0.9628409644527313\n",
            "Kappa: 0.9561500885124725\n",
            "kNN Pesos - K=5 - p=1 - it=3\n",
            "Acc: 0.96171802054155\n",
            "F1: 0.9624769855036949\n",
            "Kappa: 0.9561517454472735\n",
            "kNN Pesos - K=9 - p=1 - it=3\n",
            "Acc: 0.9542483660130717\n",
            "F1: 0.955100601843212\n",
            "Kappa: 0.9475903232706159\n"
          ]
        }
      ],
      "source": [
        "for i in [1,3,5,9]:\n",
        "    print(\"kNN Pesos - K=\"+str(i)+\" - p=1 - it=3\")\n",
        "    print(\"Acc: \" + str(knn_pesos_val_1[\"k_\" + str(i)][0][0]))\n",
        "    print(\"F1: \" + str(knn_pesos_val_1[\"k_\" + str(i)][0][1]))\n",
        "    print(\"Kappa: \" + str(knn_pesos_val_1[\"k_\" + str(i)][0][2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kNN Pesos - K=1 - p=2 - it=3\n",
            "Acc: 0.9701213818860878\n",
            "F1: 0.9714058339779555\n",
            "Kappa: 0.9657707798960026\n",
            "kNN Pesos - K=3 - p=2 - it=3\n",
            "Acc: 0.96171802054155\n",
            "F1: 0.9628409644527313\n",
            "Kappa: 0.9561500885124725\n",
            "kNN Pesos - K=5 - p=2 - it=3\n",
            "Acc: 0.96171802054155\n",
            "F1: 0.9624769855036949\n",
            "Kappa: 0.9561517454472735\n",
            "kNN Pesos - K=9 - p=2 - it=3\n",
            "Acc: 0.9542483660130717\n",
            "F1: 0.955100601843212\n",
            "Kappa: 0.9475903232706159\n"
          ]
        }
      ],
      "source": [
        "for i in [1,3,5,9]:\n",
        "    print(\"kNN Pesos - K=\"+str(i)+\" - p=2 - it=3\")\n",
        "    print(\"Acc: \" + str(knn_pesos_val_2[\"k_\" + str(i)][0][0]))\n",
        "    print(\"F1: \" + str(knn_pesos_val_2[\"k_\" + str(i)][0][1]))\n",
        "    print(\"Kappa: \" + str(knn_pesos_val_2[\"k_\" + str(i)][0][2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDtMuMOPB5x"
      },
      "source": [
        "## 5. Comparación con otros métodos (0.25 puntos)\n",
        "\n",
        "Por último, tras seleccionar los mejores parámetros para ambas versiones de kNN, vamos a comparar el rendimiento de nuestro método contra otros disponibles en scikit-learn. Para ello, entrenaremos todos los modelos utilizando el mismo conjunto de entrenamiento, y evaluaremos sobre el conjunto de test (que recordemos, no se ha utilizado aún).\n",
        "El objetivo de este notebook no es aprender cómo generar otros modelos de clasificación o analizar su funcionamiento, sino que simplemente vamos a obtener algunas métricas de evaluación de los mismos.\n",
        "\n",
        "En primer lugar, debe completar las líneas donde se genera kNN sobre los datos de entrenamiento y se evalúa sobre los de test. Simplemente tiene que incluir los parámetros que consideró que obtenían un mejor resultado según el apartado anterior.\n",
        "\n",
        "Tras completar la siguiente celda y ejecutar ambas, responda a las siguientes preguntas, en esta misma celda de texto:\n",
        "*   En los experimentos anteriores, qué knn era mejor, ¿con o sin pesos? ¿Y sobre los datos de test? ¿En ambos casos coincide que es el mismo método el mejor o no? ¿Y por qué crees que ocurre?. **RESPUESTA**: \n",
        "*   De todos los métodos evaluados sobre datos de test, ¿cuál obtiene mejores resultados? **RESPUESTA**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "p12RVKRwQSpR"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento y evaluación de kNN, utilizando datos de test para evaluar\n",
        "\n",
        "from sklearn.metrics import *\n",
        "\n",
        "# Funcion para calcular métricas de interés, e imprimirlas por pantalla\n",
        "def evaluar_e_imprimir(y_test, y_pred):\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print('   acc: ' + str(accuracy))\n",
        "  f1 = f1_score(y_test, y_pred, average='macro')\n",
        "  print('   f1: ' + str(f1))\n",
        "  kappa = cohen_kappa_score(y_test, y_pred)\n",
        "  print('   kappa: ' + str(kappa))\n",
        "\n",
        "# Valores de clases\n",
        "clases = y.unique()\n",
        "\n",
        "# Evaluar knn básico \n",
        "# COMPLETAR los ... con valores de correspondientes\n",
        "knn_proba = knn(X_train, y_train, X_test, k=1, p=1, clases=clases)\n",
        "knn_pred = class_from_pred(knn_proba, clases, seed=0)\n",
        "print('kNN básico')\n",
        "evaluar_e_imprimir(y_test, knn_pred)\n",
        "\n",
        "# Evaluar knn básico \n",
        "# COMPLETAR con valores de correspondientes\n",
        "knn_pesos_proba = knn_pesos(X_train, y_train, X_test, k=..., p=..., clases=clases)\n",
        "knn_pesos_pred = class_from_pred(knn_pesos_proba, clases, seed=0)\n",
        "print('\\nkNN con pesos')\n",
        "evaluar_e_imprimir(y_test, knn_pesos_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV7jBNcEUcxD"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento de otros métodos (simplemente ejecutar y analizar resultados)\n",
        "\n",
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_pred = GaussianNB().fit(X_train, y_train).predict(X_test)\n",
        "print('\\nNaïve Bayes')\n",
        "evaluar_e_imprimir(y_test, nb_pred)\n",
        "\n",
        "# Árbol de decisión\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_pred = DecisionTreeClassifier(random_state=0).fit(X_train, y_train).predict(X_test)\n",
        "print('\\nÁrbol de decisión')\n",
        "evaluar_e_imprimir(y_test, dt_pred)\n",
        "\n",
        "# Análisis discriminante lineal\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda_pred = LinearDiscriminantAnalysis().fit(X_train, y_train).predict(X_test)\n",
        "print('\\nAnálisis discriminante lineal')\n",
        "evaluar_e_imprimir(y_test, lda_pred)\n",
        "\n",
        "# Regresión logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_pred = LogisticRegression(random_state=0, max_iter=1000, multi_class='multinomial').fit(X_train, y_train).predict(X_test)\n",
        "print('\\nRegresión logística')\n",
        "evaluar_e_imprimir(y_test, lr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MetodosPredictivos-TareaSemana4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
