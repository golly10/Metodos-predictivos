{"cells":[{"cell_type":"markdown","metadata":{"id":"fv6Xfdv5gkBG"},"source":["# Métodos predictivos: tarea de asignación (semana 1)\n","Ya conoces el método de los mínimos cuadrados y cómo se puede utilizar para ajustar un modelo lineal con las librerías *statsmodels* y *scikit-learn*. El objetivo de esta tarea es complementar el estudio de este método de regresión abordando la evaluación del modelo de regresión obtenido."]},{"cell_type":"markdown","metadata":{"id":"4VQ3pnwChJzK"},"source":["## Descripción de la tarea\n","La tarea consta de tres apartados:\n","1.   Evaluación del método de los mínimos cuadrados en *statsmodel*: Estudia la API para obtener más información sobre la calidad de la estimación de los coeficientes (errores estándar, p-values, intervalos de confianza, etc.)\n","2. Cálculo de medidas de error en *Python*: Codifica funciones que permitan calcular las medidas MAE, MSE y RMSE.\n","3. Evaluación del método de los mínimos cuadrados en *scikit-learn*: Consulta las medidas de evaluación disponibles en el paquete [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) y comprueba que los resultados obtenidos en el apartado anterior coinciden.\n","\n","## Instrucciones\n","A lo largo del *notebook* encontrarás varios apartados con el comentario **COMPLETAR**. Añade el código necesario para realizar lo que se pide en dicho apartado. Es recomendable utilizar la función *print* para visualizar el resultado cuando se calculen las medidas de evaluación. En algunos apartados también deberás incluir una descripción textual explicando lo observado en los resultados.\n"]},{"cell_type":"markdown","metadata":{"id":"NwRpSkEWrlnQ"},"source":["## 1. Evaluación del método de los mínimos cuadrados en *statsmodels*\n","Paso 1.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2862,"status":"ok","timestamp":1629714939666,"user":{"displayName":"Aurora Ramírez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzcxAxwv8m0u1cM-3hPRQM3R0KAJS_z5UHNgSl=s64","userId":"02113171337255898555"},"user_tz":-120},"id":"2fhR1bgYrjqb","outputId":"e4a7343c-7a67-4432-a9c2-ff2753c2770a"},"outputs":[],"source":["import numpy as np\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"xU-iY4tLtE-Z"},"source":["Paso 1.2: Genera una muestra aleatoria"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"a86vFoXhvcEQ"},"outputs":[],"source":["tam_muestra = 100\n","x = np.arange(0, tam_muestra, step=1)\n","y = x*3 + 5 + np.random.normal(0,1,tam_muestra)"]},{"cell_type":"markdown","metadata":{"id":"cusEl0Xc5Y4C"},"source":["Paso 1.3: Ejecuta el método de los mínimos cuadrados"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"2PTlF-EG58gB"},"outputs":[],"source":["x = sm.add_constant(x)\n","algoritmo = sm.OLS(y,x)\n","modelo_regresion = algoritmo.fit()"]},{"cell_type":"markdown","metadata":{"id":"XaiZ0yDypKz2"},"source":["Paso 1.4: Extrae el error estándar asociado a cada coeficiente y calcula el intervalo de confianza."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xtct2pZjpT5R"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intercepto:  5.088707536219634\n","Intercepto - Error estandar:  0.21047802112228628\n","Intercepto - Intervalo de confianza:  [4.67102075 5.50639432]\n","\n","Pendiente:  2.9947557521358616\n","Pendiente - Error estandar:  0.0036731464281555704\n","Pendiente - Intervalo de confianza:  [2.98746651 3.00204499]\n"]}],"source":["#COMPLETAR\n","\n","intercept, slope = modelo_regresion.params[0], modelo_regresion.params[1]\n","\n","intercept_std_err, slope_std_err = modelo_regresion.bse[0], modelo_regresion.bse[1]\n","\n","intercept_conf_int, slope_conf_int = modelo_regresion.conf_int()[0], modelo_regresion.conf_int()[1]\n","\n","print(\"Intercepto: \", str(intercept))\n","print(\"Intercepto - Error estandar: \", str(intercept_std_err))\n","print(\"Intercepto - Intervalo de confianza: \", str(intercept_conf_int))\n","print(\"\")\n","print(\"Pendiente: \", str(slope))\n","print(\"Pendiente - Error estandar: \", str(slope_std_err))\n","print(\"Pendiente - Intervalo de confianza: \", str(slope_conf_int))"]},{"cell_type":"markdown","metadata":{"id":"ZnhdREaAl0SU"},"source":["Paso 1.5: Utiliza la función ***summary*** para analizar la calidad de la estimación de los coeficientes."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"aQm8W49wl0CR"},"outputs":[{"name":"stdout","output_type":"stream","text":["p_value obtenido para intercepto: 4.3299965924038745e-43\n","p_value obtenido para pendiente: 1.453854181290093e-189\n"]},{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.647e+05</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Thu, 20 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>1.45e-189</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>17:42:23</td>     <th>  Log-Likelihood:    </th> <td> -146.74</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   297.5</td> \n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   302.7</td> \n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>    5.0887</td> <td>    0.210</td> <td>   24.177</td> <td> 0.000</td> <td>    4.671</td> <td>    5.506</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    2.9948</td> <td>    0.004</td> <td>  815.311</td> <td> 0.000</td> <td>    2.987</td> <td>    3.002</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.907</td> <th>  Durbin-Watson:     </th> <td>   2.060</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.635</td> <th>  Jarque-Bera (JB):  </th> <td>   0.967</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.217</td> <th>  Prob(JB):          </th> <td>   0.617</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 2.791</td> <th>  Cond. No.          </th> <td>    114.</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       1.000\n","Model:                            OLS   Adj. R-squared:                  1.000\n","Method:                 Least Squares   F-statistic:                 6.647e+05\n","Date:                Thu, 20 Jan 2022   Prob (F-statistic):          1.45e-189\n","Time:                        17:42:23   Log-Likelihood:                -146.74\n","No. Observations:                 100   AIC:                             297.5\n","Df Residuals:                      98   BIC:                             302.7\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const          5.0887      0.210     24.177      0.000       4.671       5.506\n","x1             2.9948      0.004    815.311      0.000       2.987       3.002\n","==============================================================================\n","Omnibus:                        0.907   Durbin-Watson:                   2.060\n","Prob(Omnibus):                  0.635   Jarque-Bera (JB):                0.967\n","Skew:                          -0.217   Prob(JB):                        0.617\n","Kurtosis:                       2.791   Cond. No.                         114.\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#COMPLETAR\n","print(\"p_value obtenido para intercepto: \" + str(modelo_regresion.pvalues[0]))\n","print(\"p_value obtenido para pendiente: \" + str(modelo_regresion.pvalues[1]))\n","modelo_regresion.summary()"]},{"cell_type":"markdown","metadata":{"id":"wwGNSTh4ml6q"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","Observando los resultados del modelo, se pueden observar los siguientes puntos:\n"," - Las variables presentan una relación lineal positiva. Ya que la __pendiente__ es mayor que 0.\n"," - Podemos observar además, que los intervalos de confianza son bastante pequeños, lo que nos indica que la predicción es bastante precisa, siendo mejor en la pendiente que en el intercepto.\n"," - Finalmente, podemos confirmar que existe una __relación lineal__ entre las dos variables __x__ e __y__, con bastante probabilidad (95% de confianza), ya que el valor de __p_value__ es menor que el nivel de significancia (0,05)."]},{"cell_type":"markdown","metadata":{"id":"plganWApTE65"},"source":["## 2. Cálculo de medidas de error en *Python*\n","Codifica tres funciones para calcular las medidas MAE, MSE y RMSE a partir de los valores estimados y reales de *y*. El código **no** debe utilizar las librerías *statsmodels* ni *scikit-learn*."]},{"cell_type":"markdown","metadata":{"id":"1ZBgge4BrluU"},"source":["Paso 2.1: Implementa una función que calcule la medida de error MAE."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ak23fq7urGqm"},"outputs":[],"source":["# COMPLETAR\n","def calculate_mae(y, y_pred):\n","\n","    sum_val = np.sum([abs(y_i - y_i_pred) for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / len(y)"]},{"cell_type":"markdown","metadata":{"id":"8m5a-eU5rrU0"},"source":["Paso 2.2: Implementa una función que calcule la medida de error MSE."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"gI2GfPxQrGKp"},"outputs":[],"source":["# COMPLETAR\n","\n","def calculate_mse(y, y_pred):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / len(y)"]},{"cell_type":"markdown","metadata":{"id":"OLubCXB4rug7"},"source":["Paso 2.3: Implementa una función para calcular la medida de error RMSE."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"yXetIREtrxfQ"},"outputs":[],"source":["# COMPLETAR\n","def calculate_rmse(y, y_pred):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","        \n","    sum_val /= len(y)\n","\n","    return np.sqrt(sum_val)\n"]},{"cell_type":"markdown","metadata":{"id":"zB6Vot_at2dF"},"source":["## 3. Evaluación del método de los mínimos cuadrados en *scikit-learn*\n"]},{"cell_type":"markdown","metadata":{"id":"7B6H-zjxucOz"},"source":["Paso 3.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Ibz5RsBbUHI2"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"eLiQkHwXeN0A"},"source":["Paso 3.2: Separa la muestra en partición de entrenamiento (33%) y test. Utilizar la partición de entrenamiento para ajustar el modelo."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"JNhJBjgmefxR"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n","alg_regresion = LinearRegression()\n","modelo_regresion = alg_regresion.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"24ZT9SZ_fXC8"},"source":["Paso 3.3: Obtén los valores *y* estimados para la partición de test"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"hzMQKjD7vyVo"},"outputs":[],"source":["# COMPLETAR\n","y_pred = modelo_regresion.predict(x_test)"]},{"cell_type":"markdown","metadata":{"id":"GSCNeOg0v4s-"},"source":["Paso 3.4: Calcula MAE, MSE y RMSE utilizando las funciones implementadas en el apartado anterior."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Skiym0Q8v3WK"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.9370983905549901\n","MSE -> 1.195085613927169\n","RMSE -> 1.0931997136512472\n"]}],"source":["# COMPLETAR\n","\n","mae = calculate_mae(y_test, y_pred)\n","mse = calculate_mse(y_test, y_pred)\n","rmse = calculate_rmse(y_test, y_pred)\n","\n","print(\"MAE -> \" + str(mae))\n","print(\"MSE -> \" + str(mse))\n","print(\"RMSE -> \" + str(rmse))"]},{"cell_type":"markdown","metadata":{"id":"pFRq9T0IgCLa"},"source":["Paso 3.5: Comprueba, utilizando las funciones de *scikit-learn*, que los valores de MAE y MSE coinciden con los devueltos por las funciones implementadas."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"WoB8GNNawpd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.9370983905549901\n","MSE -> 1.195085613927169\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","print(\"MAE -> \" + str(mean_absolute_error(y_test, y_pred)))\n","print(\"MSE -> \" + str(mean_squared_error(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"v45tJaWnxLf6"},"source":["Paso 3.6: Calcula el estadístico R2 (utilizando la función adecuada de *scikit-learn*) y analiza su significado."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"k5Kk1WkagOaz"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 -> 0.9998137017903105\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import r2_score\n","\n","print(\"R2 -> \" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"ujXA-xYfxm7v"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","De los resultados obtenidos podemos sacar las siguientes conclusiones:\n","- Los errores obtenidos a través de las métricas calculadas son bastante altos.\n","- No obstante, a través del estadístico R2, podemos observar que, la recta de regresión explica, con bastante precisión, la relación existente entre los valores de __x__ e __y__, ya que el valor de R2 está muy próximo a 1. "]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPsTzg9b7RDkfky4Ac99Yhp","collapsed_sections":[],"name":"MetodosPredictivos-NotebookTareaSemana1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
