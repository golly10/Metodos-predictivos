{"cells":[{"cell_type":"markdown","metadata":{"id":"fv6Xfdv5gkBG"},"source":["# Métodos predictivos: tarea de asignación (semana 1)\n","Ya conoces el método de los mínimos cuadrados y cómo se puede utilizar para ajustar un modelo lineal con las librerías *statsmodels* y *scikit-learn*. El objetivo de esta tarea es complementar el estudio de este método de regresión abordando la evaluación del modelo de regresión obtenido."]},{"cell_type":"markdown","metadata":{"id":"4VQ3pnwChJzK"},"source":["## Descripción de la tarea\n","La tarea consta de tres apartados:\n","1.   Evaluación del método de los mínimos cuadrados en *statsmodel*: Estudia la API para obtener más información sobre la calidad de la estimación de los coeficientes (errores estándar, p-values, intervalos de confianza, etc.)\n","2. Cálculo de medidas de error en *Python*: Codifica funciones que permitan calcular las medidas MAE, MSE y RMSE.\n","3. Evaluación del método de los mínimos cuadrados en *scikit-learn*: Consulta las medidas de evaluación disponibles en el paquete [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) y comprueba que los resultados obtenidos en el apartado anterior coinciden.\n","\n","## Instrucciones\n","A lo largo del *notebook* encontrarás varios apartados con el comentario **COMPLETAR**. Añade el código necesario para realizar lo que se pide en dicho apartado. Es recomendable utilizar la función *print* para visualizar el resultado cuando se calculen las medidas de evaluación. En algunos apartados también deberás incluir una descripción textual explicando lo observado en los resultados.\n"]},{"cell_type":"markdown","metadata":{"id":"NwRpSkEWrlnQ"},"source":["## 1. Evaluación del método de los mínimos cuadrados en *statsmodels*\n","Paso 1.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2862,"status":"ok","timestamp":1629714939666,"user":{"displayName":"Aurora Ramírez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzcxAxwv8m0u1cM-3hPRQM3R0KAJS_z5UHNgSl=s64","userId":"02113171337255898555"},"user_tz":-120},"id":"2fhR1bgYrjqb","outputId":"e4a7343c-7a67-4432-a9c2-ff2753c2770a"},"outputs":[],"source":["import numpy as np\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"xU-iY4tLtE-Z"},"source":["Paso 1.2: Genera una muestra aleatoria"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"a86vFoXhvcEQ"},"outputs":[],"source":["tam_muestra = 100\n","x = np.arange(0, tam_muestra, step=1)\n","y = x*3 + 5 + np.random.normal(0,1,tam_muestra)"]},{"cell_type":"markdown","metadata":{"id":"cusEl0Xc5Y4C"},"source":["Paso 1.3: Ejecuta el método de los mínimos cuadrados"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"2PTlF-EG58gB"},"outputs":[],"source":["x = sm.add_constant(x)\n","algoritmo = sm.OLS(y,x)\n","modelo_regresion = algoritmo.fit()"]},{"cell_type":"markdown","metadata":{"id":"XaiZ0yDypKz2"},"source":["Paso 1.4: Extrae el error estándar asociado a cada coeficiente y calcula el intervalo de confianza."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"xtct2pZjpT5R"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intercepto:  4.67124080573821\n","Intercepto - Error estandar:  0.20417983933144945\n","Intercepto - Intervalo de confianza:  [4.26605256 5.07642905]\n","\n","Pendiente:  3.003943707588569\n","Pendiente - Error estandar:  0.003563234030530709\n","Pendiente - Intervalo de confianza:  [2.99687259 3.01101483]\n"]}],"source":["#COMPLETAR\n","\n","intercept, slope = modelo_regresion.params[0], modelo_regresion.params[1]\n","\n","intercept_std_err, slope_std_err = modelo_regresion.bse[0], modelo_regresion.bse[1]\n","\n","intercept_conf_int, slope_conf_int = modelo_regresion.conf_int()[0], modelo_regresion.conf_int()[1]\n","\n","print(\"Intercepto: \", str(intercept))\n","print(\"Intercepto - Error estandar: \", str(intercept_std_err))\n","print(\"Intercepto - Intervalo de confianza: \", str(intercept_conf_int))\n","print(\"\")\n","print(\"Pendiente: \", str(slope))\n","print(\"Pendiente - Error estandar: \", str(slope_std_err))\n","print(\"Pendiente - Intervalo de confianza: \", str(slope_conf_int))"]},{"cell_type":"markdown","metadata":{"id":"ZnhdREaAl0SU"},"source":["Paso 1.5: Utiliza la función ***summary*** para analizar la calidad de la estimación de los coeficientes."]},{"cell_type":"code","execution_count":59,"metadata":{"id":"aQm8W49wl0CR"},"outputs":[{"name":"stdout","output_type":"stream","text":["p_value obtenido para intercepto: 4.328674838365314e-41\n","p_value obtenido para pendiente: 5.4870976158418945e-191\n"]},{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>7.107e+05</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Wed, 19 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>5.49e-191</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>21:33:27</td>     <th>  Log-Likelihood:    </th> <td> -143.70</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   291.4</td> \n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   296.6</td> \n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>    4.6712</td> <td>    0.204</td> <td>   22.878</td> <td> 0.000</td> <td>    4.266</td> <td>    5.076</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    3.0039</td> <td>    0.004</td> <td>  843.039</td> <td> 0.000</td> <td>    2.997</td> <td>    3.011</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.928</td> <th>  Durbin-Watson:     </th> <td>   2.240</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.629</td> <th>  Jarque-Bera (JB):  </th> <td>   0.515</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 0.143</td> <th>  Prob(JB):          </th> <td>   0.773</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 3.206</td> <th>  Cond. No.          </th> <td>    114.</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       1.000\n","Model:                            OLS   Adj. R-squared:                  1.000\n","Method:                 Least Squares   F-statistic:                 7.107e+05\n","Date:                Wed, 19 Jan 2022   Prob (F-statistic):          5.49e-191\n","Time:                        21:33:27   Log-Likelihood:                -143.70\n","No. Observations:                 100   AIC:                             291.4\n","Df Residuals:                      98   BIC:                             296.6\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const          4.6712      0.204     22.878      0.000       4.266       5.076\n","x1             3.0039      0.004    843.039      0.000       2.997       3.011\n","==============================================================================\n","Omnibus:                        0.928   Durbin-Watson:                   2.240\n","Prob(Omnibus):                  0.629   Jarque-Bera (JB):                0.515\n","Skew:                           0.143   Prob(JB):                        0.773\n","Kurtosis:                       3.206   Cond. No.                         114.\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["#COMPLETAR\n","print(\"p_value obtenido para intercepto: \" + str(modelo_regresion.pvalues[0]))\n","print(\"p_value obtenido para pendiente: \" + str(modelo_regresion.pvalues[1]))\n","modelo_regresion.summary()"]},{"cell_type":"markdown","metadata":{"id":"wwGNSTh4ml6q"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","Observando los resultados del modelo, se pueden observar los siguientes puntos:\n"," - Las variables presentan una relación lineal positiva. Ya que la __pendiente__ es mayor que 0.\n"," - Podemos observar además, que los intervalos de confianza son bastante pequeños, lo que nos indica que la predicción es bastante precisa, siendo mejor en la pendiente que en el intercepto.\n"," - También se puede observar que se asume como cierta la hipótesis de la no relación entre las variables __x__ e __y__, es decir, podemos decir que las variables están relacionadas, ya que el valor de __p-value__ es inferior al valor del umbral especificado (0.05), para ambos coeficientes."]},{"cell_type":"markdown","metadata":{"id":"plganWApTE65"},"source":["## 2. Cálculo de medidas de error en *Python*\n","Codifica tres funciones para calcular las medidas MAE, MSE y RMSE a partir de los valores estimados y reales de *y*. El código **no** debe utilizar las librerías *statsmodels* ni *scikit-learn*."]},{"cell_type":"markdown","metadata":{"id":"1ZBgge4BrluU"},"source":["Paso 2.1: Implementa una función que calcule la medida de error MAE."]},{"cell_type":"code","execution_count":60,"metadata":{"id":"ak23fq7urGqm"},"outputs":[],"source":["# COMPLETAR\n","def calculate_mae(y, y_pred, n):\n","\n","    sum_val = np.sum([abs(y_i - y_i_pred) for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / n"]},{"cell_type":"markdown","metadata":{"id":"8m5a-eU5rrU0"},"source":["Paso 2.2: Implementa una función que calcule la medida de error MSE."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"gI2GfPxQrGKp"},"outputs":[],"source":["# COMPLETAR\n","\n","def calculate_mse(y, y_pred, n):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / n"]},{"cell_type":"markdown","metadata":{"id":"OLubCXB4rug7"},"source":["Paso 2.3: Implementa una función para calcular la medida de error RMSE."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"yXetIREtrxfQ"},"outputs":[],"source":["# COMPLETAR\n","def calculate_rmse(y, y_pred, n):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","        \n","    sum_val /= n\n","\n","    return np.sqrt(sum_val)\n"]},{"cell_type":"markdown","metadata":{"id":"zB6Vot_at2dF"},"source":["## 3. Evaluación del método de los mínimos cuadrados en *scikit-learn*\n"]},{"cell_type":"markdown","metadata":{"id":"7B6H-zjxucOz"},"source":["Paso 3.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"Ibz5RsBbUHI2"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"eLiQkHwXeN0A"},"source":["Paso 3.2: Separa la muestra en partición de entrenamiento (33%) y test. Utilizar la partición de entrenamiento para ajustar el modelo."]},{"cell_type":"code","execution_count":64,"metadata":{"id":"JNhJBjgmefxR"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n","alg_regresion = LinearRegression()\n","modelo_regresion = alg_regresion.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"24ZT9SZ_fXC8"},"source":["Paso 3.3: Obtén los valores *y* estimados para la partición de test"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"hzMQKjD7vyVo"},"outputs":[],"source":["# COMPLETAR\n","y_pred = modelo_regresion.predict(x_test)"]},{"cell_type":"markdown","metadata":{"id":"GSCNeOg0v4s-"},"source":["Paso 3.4: Calcula MAE, MSE y RMSE utilizando las funciones implementadas en el apartado anterior."]},{"cell_type":"code","execution_count":66,"metadata":{"id":"Skiym0Q8v3WK"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.7281740586533155\n","MSE -> 0.8629759171782825\n","RMSE -> 0.9289649709102504\n"]}],"source":["# COMPLETAR\n","\n","mae = calculate_mae(y_test, y_pred, len(y_test))\n","mse = calculate_mse(y_test, y_pred, len(y_test))\n","rmse = calculate_rmse(y_test, y_pred, len(y_test))\n","\n","print(\"MAE -> \" + str(mae))\n","print(\"MSE -> \" + str(mse))\n","print(\"RMSE -> \" + str(rmse))"]},{"cell_type":"markdown","metadata":{"id":"pFRq9T0IgCLa"},"source":["Paso 3.5: Comprueba, utilizando las funciones de *scikit-learn*, que los valores de MAE y MSE coinciden con los devueltos por las funciones implementadas."]},{"cell_type":"code","execution_count":67,"metadata":{"id":"WoB8GNNawpd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.7281740586533155\n","MSE -> 0.8629759171782825\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","print(\"MAE -> \" + str(mean_absolute_error(y_test, y_pred)))\n","print(\"MSE -> \" + str(mean_squared_error(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"v45tJaWnxLf6"},"source":["Paso 3.6: Calcula el estadístico R2 (utilizando la función adecuada de *scikit-learn*) y analiza su significado."]},{"cell_type":"code","execution_count":68,"metadata":{"id":"k5Kk1WkagOaz"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 -> 0.9998819617744095\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import r2_score\n","\n","print(\"R2 -> \" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"ujXA-xYfxm7v"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","De los resultados obtenidos podemos sacar las siguientes conclusiones:\n","- Los errores obtenidos a través de las métricas calculadas son bastante altos.\n","- No obstante, a través del estadístico R2, podemos observar que, la recta de regresión explica con bastante precisión la relación existente entre las etiquetas reales y la predichas, ya que el valor de R2 está muy próximo a 1. "]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPsTzg9b7RDkfky4Ac99Yhp","collapsed_sections":[],"name":"MetodosPredictivos-NotebookTareaSemana1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
