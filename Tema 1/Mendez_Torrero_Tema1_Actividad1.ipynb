{"cells":[{"cell_type":"markdown","metadata":{"id":"fv6Xfdv5gkBG"},"source":["# Métodos predictivos: tarea de asignación (semana 1)\n","Ya conoces el método de los mínimos cuadrados y cómo se puede utilizar para ajustar un modelo lineal con las librerías *statsmodels* y *scikit-learn*. El objetivo de esta tarea es complementar el estudio de este método de regresión abordando la evaluación del modelo de regresión obtenido."]},{"cell_type":"markdown","metadata":{"id":"4VQ3pnwChJzK"},"source":["## Descripción de la tarea\n","La tarea consta de tres apartados:\n","1.   Evaluación del método de los mínimos cuadrados en *statsmodel*: Estudia la API para obtener más información sobre la calidad de la estimación de los coeficientes (errores estándar, p-values, intervalos de confianza, etc.)\n","2. Cálculo de medidas de error en *Python*: Codifica funciones que permitan calcular las medidas MAE, MSE y RMSE.\n","3. Evaluación del método de los mínimos cuadrados en *scikit-learn*: Consulta las medidas de evaluación disponibles en el paquete [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) y comprueba que los resultados obtenidos en el apartado anterior coinciden.\n","\n","## Instrucciones\n","A lo largo del *notebook* encontrarás varios apartados con el comentario **COMPLETAR**. Añade el código necesario para realizar lo que se pide en dicho apartado. Es recomendable utilizar la función *print* para visualizar el resultado cuando se calculen las medidas de evaluación. En algunos apartados también deberás incluir una descripción textual explicando lo observado en los resultados.\n"]},{"cell_type":"markdown","metadata":{"id":"NwRpSkEWrlnQ"},"source":["## 1. Evaluación del método de los mínimos cuadrados en *statsmodels*\n","Paso 1.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2862,"status":"ok","timestamp":1629714939666,"user":{"displayName":"Aurora Ramírez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzcxAxwv8m0u1cM-3hPRQM3R0KAJS_z5UHNgSl=s64","userId":"02113171337255898555"},"user_tz":-120},"id":"2fhR1bgYrjqb","outputId":"e4a7343c-7a67-4432-a9c2-ff2753c2770a"},"outputs":[],"source":["import numpy as np\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"xU-iY4tLtE-Z"},"source":["Paso 1.2: Genera una muestra aleatoria"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"a86vFoXhvcEQ"},"outputs":[],"source":["tam_muestra = 100\n","x = np.arange(0, tam_muestra, step=1)\n","y = x*3 + 5 + np.random.normal(0,1,tam_muestra)"]},{"cell_type":"markdown","metadata":{"id":"cusEl0Xc5Y4C"},"source":["Paso 1.3: Ejecuta el método de los mínimos cuadrados"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2PTlF-EG58gB"},"outputs":[],"source":["x = sm.add_constant(x)\n","algoritmo = sm.OLS(y,x)\n","modelo_regresion = algoritmo.fit()"]},{"cell_type":"markdown","metadata":{"id":"XaiZ0yDypKz2"},"source":["Paso 1.4: Extrae el error estándar asociado a cada coeficiente y calcula el intervalo de confianza."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xtct2pZjpT5R"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intercepto:  5.0609998792371975\n","Intercepto - Error estandar:  0.18348047139690965\n","Intercepto - Intervalo de confianza:  [4.69688886 5.4251109 ]\n","\n","Pendiente:  2.999653617131855\n","Pendiente - Error estandar:  0.0032020000689587363\n","Pendiente - Intervalo de confianza:  [2.99329935 3.00600788]\n"]}],"source":["#COMPLETAR\n","\n","intercept, slope = modelo_regresion.params[0], modelo_regresion.params[1]\n","\n","intercept_std_err, slope_std_err = modelo_regresion.bse[0], modelo_regresion.bse[1]\n","\n","intercept_conf_int, slope_conf_int = modelo_regresion.conf_int()[0], modelo_regresion.conf_int()[1]\n","\n","print(\"Intercepto: \", str(intercept))\n","print(\"Intercepto - Error estandar: \", str(intercept_std_err))\n","print(\"Intercepto - Intervalo de confianza: \", str(intercept_conf_int))\n","print(\"\")\n","print(\"Pendiente: \", str(slope))\n","print(\"Pendiente - Error estandar: \", str(slope_std_err))\n","print(\"Pendiente - Intervalo de confianza: \", str(slope_conf_int))"]},{"cell_type":"markdown","metadata":{"id":"ZnhdREaAl0SU"},"source":["Paso 1.5: Utiliza la función ***summary*** para analizar la calidad de la estimación de los coeficientes."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aQm8W49wl0CR"},"outputs":[{"name":"stdout","output_type":"stream","text":["p_value obtenido para intercepto: 5.487369238412681e-48\n","p_value obtenido para pendiente: 1.783474399876273e-195\n"]},{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>8.776e+05</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Sat, 22 Jan 2022</td> <th>  Prob (F-statistic):</th> <td>1.78e-195</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>09:17:51</td>     <th>  Log-Likelihood:    </th> <td> -133.01</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   270.0</td> \n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   275.2</td> \n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>    5.0610</td> <td>    0.183</td> <td>   27.583</td> <td> 0.000</td> <td>    4.697</td> <td>    5.425</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    2.9997</td> <td>    0.003</td> <td>  936.806</td> <td> 0.000</td> <td>    2.993</td> <td>    3.006</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.875</td> <th>  Durbin-Watson:     </th> <td>   2.030</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.646</td> <th>  Jarque-Bera (JB):  </th> <td>   0.989</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 0.188</td> <th>  Prob(JB):          </th> <td>   0.610</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 2.689</td> <th>  Cond. No.          </th> <td>    114.</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       1.000\n","Model:                            OLS   Adj. R-squared:                  1.000\n","Method:                 Least Squares   F-statistic:                 8.776e+05\n","Date:                Sat, 22 Jan 2022   Prob (F-statistic):          1.78e-195\n","Time:                        09:17:51   Log-Likelihood:                -133.01\n","No. Observations:                 100   AIC:                             270.0\n","Df Residuals:                      98   BIC:                             275.2\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const          5.0610      0.183     27.583      0.000       4.697       5.425\n","x1             2.9997      0.003    936.806      0.000       2.993       3.006\n","==============================================================================\n","Omnibus:                        0.875   Durbin-Watson:                   2.030\n","Prob(Omnibus):                  0.646   Jarque-Bera (JB):                0.989\n","Skew:                           0.188   Prob(JB):                        0.610\n","Kurtosis:                       2.689   Cond. No.                         114.\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#COMPLETAR\n","print(\"p_value obtenido para intercepto: \" + str(modelo_regresion.pvalues[0]))\n","print(\"p_value obtenido para pendiente: \" + str(modelo_regresion.pvalues[1]))\n","modelo_regresion.summary()"]},{"cell_type":"markdown","metadata":{"id":"wwGNSTh4ml6q"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","Observando los resultados del modelo, se pueden observar los siguientes puntos:\n"," - Las variables presentan una relación lineal positiva. Ya que la __pendiente__ es mayor que 0.\n"," - Podemos observar además, que los intervalos de confianza son bastante pequeños, lo que nos indica que la predicción es bastante precisa, siendo mejor en la pendiente que en el intercepto.\n"," - Finalmente, podemos confirmar que existe una __relación lineal__ entre las dos variables __x__ e __y__, con bastante probabilidad (95% de confianza), ya que el valor de __p_value__ es menor que el nivel de significancia (0,05)."]},{"cell_type":"markdown","metadata":{"id":"plganWApTE65"},"source":["## 2. Cálculo de medidas de error en *Python*\n","Codifica tres funciones para calcular las medidas MAE, MSE y RMSE a partir de los valores estimados y reales de *y*. El código **no** debe utilizar las librerías *statsmodels* ni *scikit-learn*."]},{"cell_type":"markdown","metadata":{"id":"1ZBgge4BrluU"},"source":["Paso 2.1: Implementa una función que calcule la medida de error MAE."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ak23fq7urGqm"},"outputs":[],"source":["# COMPLETAR\n","def calculate_mae(y, y_pred):\n","\n","    sum_val = np.sum([abs(y_i - y_i_pred) for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / len(y)"]},{"cell_type":"markdown","metadata":{"id":"8m5a-eU5rrU0"},"source":["Paso 2.2: Implementa una función que calcule la medida de error MSE."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gI2GfPxQrGKp"},"outputs":[],"source":["# COMPLETAR\n","\n","def calculate_mse(y, y_pred):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","\n","    return sum_val / len(y)"]},{"cell_type":"markdown","metadata":{"id":"OLubCXB4rug7"},"source":["Paso 2.3: Implementa una función para calcular la medida de error RMSE."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"yXetIREtrxfQ"},"outputs":[],"source":["# COMPLETAR\n","def calculate_rmse(y, y_pred):\n","    \n","    sum_val = np.sum([(y_i - y_i_pred)**2 for y_i, y_i_pred in zip(y, y_pred)])\n","        \n","    sum_val /= len(y)\n","\n","    return np.sqrt(sum_val)\n"]},{"cell_type":"markdown","metadata":{"id":"zB6Vot_at2dF"},"source":["## 3. Evaluación del método de los mínimos cuadrados en *scikit-learn*\n"]},{"cell_type":"markdown","metadata":{"id":"7B6H-zjxucOz"},"source":["Paso 3.1: Importa los paquetes necesarios"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Ibz5RsBbUHI2"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"eLiQkHwXeN0A"},"source":["Paso 3.2: Separa la muestra en partición de entrenamiento (33%) y test. Utilizar la partición de entrenamiento para ajustar el modelo."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JNhJBjgmefxR"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n","alg_regresion = LinearRegression()\n","modelo_regresion = alg_regresion.fit(x_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"24ZT9SZ_fXC8"},"source":["Paso 3.3: Obtén los valores *y* estimados para la partición de test"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"hzMQKjD7vyVo"},"outputs":[],"source":["# COMPLETAR\n","y_pred = modelo_regresion.predict(x_test)"]},{"cell_type":"markdown","metadata":{"id":"GSCNeOg0v4s-"},"source":["Paso 3.4: Calcula MAE, MSE y RMSE utilizando las funciones implementadas en el apartado anterior."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Skiym0Q8v3WK"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.7766164744337903\n","MSE -> 0.8372192820858138\n","RMSE -> 0.914996875451394\n"]}],"source":["# COMPLETAR\n","\n","mae = calculate_mae(y_test, y_pred)\n","mse = calculate_mse(y_test, y_pred)\n","rmse = calculate_rmse(y_test, y_pred)\n","\n","print(\"MAE -> \" + str(mae))\n","print(\"MSE -> \" + str(mse))\n","print(\"RMSE -> \" + str(rmse))"]},{"cell_type":"markdown","metadata":{"id":"pFRq9T0IgCLa"},"source":["Paso 3.5: Comprueba, utilizando las funciones de *scikit-learn*, que los valores de MAE y MSE coinciden con los devueltos por las funciones implementadas."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WoB8GNNawpd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE -> 0.7766164744337903\n","MSE -> 0.8372192820858138\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","print(\"MAE -> \" + str(mean_absolute_error(y_test, y_pred)))\n","print(\"MSE -> \" + str(mean_squared_error(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"v45tJaWnxLf6"},"source":["Paso 3.6: Calcula el estadístico R2 (utilizando la función adecuada de *scikit-learn*) y analiza su significado."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"k5Kk1WkagOaz"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 -> 0.9998666205263225\n"]}],"source":["# COMPLETAR\n","from sklearn.metrics import r2_score\n","\n","print(\"R2 -> \" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"ujXA-xYfxm7v"},"source":["*Añade aquí una breve explicación de lo observado.*\n","\n","De los resultados obtenidos podemos sacar las siguientes conclusiones:\n","- Los errores obtenidos a través de las métricas calculadas son bastante altos.\n","- No obstante, a través del estadístico R2, podemos observar que, la recta de regresión explica, con bastante precisión, la relación existente entre los valores de __x__ e __y__, ya que el valor de R2 está muy próximo a 1. "]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPsTzg9b7RDkfky4Ac99Yhp","collapsed_sections":[],"name":"MetodosPredictivos-NotebookTareaSemana1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
