{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk9mtJJOegTX"
      },
      "source": [
        "# Métodos predictivos: tarea de asignación (semana 5)\n",
        "## Implementación de clasificadores basados en ensembles.\n",
        "\n",
        "## Instrucciones\n",
        "En este notebook encontrarás los pasos necesarios para realizar la tarea de la 5ª semana de Métodos Predictivos del Máster en Ciencia de Datos. Lea detenidamente y siga los pasos indicados en las siguientes celdas, complete el código donde se indique ``# COMPLETAR AQUI``, respetando el formato o los nombres de funciones especificados.\n",
        "\n",
        "## Descripción de la tarea\n",
        "En esta tarea, el principal objetivo será implementar métodos basados en ensemble, utilizando distintos métodos de combinación, así como analizar su comportamiento y resultados en un estudio experimental. La tarea consta de varios apartados:\n",
        "0. Carga y preparación de datos\n",
        "1. Combinación por voto mayoritario (0.5 punto)\n",
        "2. Combinación de probabilidades (0.5 punto)\n",
        "3. Creación de ensemble tipo *bagging* (2.5 puntos)\n",
        "4. Estudio experimental y análisis (1.5 puntos)\n",
        "\n",
        "**NOTA**: A lo largo de toda la tarea se proponen distintas funciones con ciertos parámetros. Cualquier parámetro de cualquiera de las funciones que considere oportuno añadir, modificar, o eliminar, puede hacerlo siempre que justifique su elección correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYvOzHcZtG89"
      },
      "source": [
        "Rellenar esta celda con los datos del alumno\n",
        "\n",
        "**Nombre**: \n",
        "\n",
        "**Apellidos**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3dHp9YUe8RD"
      },
      "source": [
        "## 0. Carga y preparación de datos\n",
        "\n",
        "En primer lugar, en esta sección el estudiante debe cargar los datos que utilizará a lo largo del *notebook*. En este caso, no se indica o restringe a utilizar unos datos concretos, sino que el estudiante puede escoger los datos que considere, siempre y cuando se trate de conjuntos de datos para clasificación. La única restricción es no utilizar un conjunto de datos de los utilizados en *notebooks* anteriores de la asignatura.\n",
        "\n",
        "Se pueden utilizar conjuntos de datos tanto de clasificación binaria como multi-clase. Sin embargo, por simplicidad de implementación, se recomienda utilizar de clasificación binaria (aunque si el estudiante desea utilizar multi-clase, no hay problema). En caso de escoger problemas binarios, puede: 1) utilizar directamente un conjunto de datos binario; o 2) cargar un conjunto de datos multi-clase y filtrar sus patrones para dejar unicamente aquellos pertenecientes a dos clases, convirtiéndolo en un problema binario más pequeño.\n",
        "\n",
        "Una vez cargados los datos, el estudiante deberá considerar si necesita realizar algún preprocesado de los mismos (si lo considera necesario), y deberá realizar una partición de los datos en entrenamiento y test.\n",
        "\n",
        "Además, sería oportuno imprimir por pantalla algunas características de los datos, como el número de patrones de entrenamiento/test y el número de clases distintas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Zb8ISLewbTH"
      },
      "outputs": [],
      "source": [
        "# Carga de datos, preprocesado (si es necesario), y partición en train-test\n",
        "\n",
        "# COMPLETAR AQUI\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\", sep=\",\")\n",
        "data\n",
        "y = data[\"R\"]\n",
        "\n",
        "X = data.drop([\"R\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El número de patrones para el conjunto de entremanieto es: 138\n",
            "El número de patrones para el conjunto de test es: 69\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"El número de patrones para el conjunto de entremanieto es: {0}\".format(len(X_train)))\n",
        "print(\"El número de patrones para el conjunto de test es: {0}\".format(len(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSzFWxAh94Py"
      },
      "source": [
        "## 1. Combinación por voto mayoritario (0.5 puntos)\n",
        "\n",
        "En primer lugar, implementaremos una función para obtener la decisión final del ensemble para un patrón dado, por el método de voto mayoritario. En este caso, la salida debe ofrecer no la clase categórica, sino la probabilidad de pertenencia a la clase considerada positiva (ratio de predicciones positivas entre el total).\n",
        "\n",
        "La función debe seguir el siguiente prototipo: ``voto_mayoritario(predicciones, pos_label)``; donde el parámetro ``predicciones`` será una lista con los valores **categóricos** de predicción de cada uno de los clasificadores base, y ``pos_label`` será el valor de clase considerado como clase positiva. La función debe devolver un único valor, que sea la probabilidad predicha de pertenencia a la clase considerada positiva\n",
        "\n",
        "Por ejemplo, si la función recibe la lista ``['P', 'N', 'N', 'P', 'P']``, (y el parámetro ``pos_label='P'``) debe devolver ``0.6``, que sería la probabilidad de pertenencia a la clase positiva (ratio de predicciones positivas entre el total).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p22Uz8ZpE6ei"
      },
      "outputs": [],
      "source": [
        "def voto_mayoritario(predicciones, pos_label=\"R\"):\n",
        "  '''\n",
        "  Método de combinación para el ensemble para un patrón por voto mayoritario\n",
        "    de las predicciones de los clasificadores base.\n",
        "  Devuelve la predicciones de pertenencia a la clase positiva, calculada como el\n",
        "    ratio de probabilidades de la clase positiva entre el total de predicciones\n",
        "\n",
        "  :param predicciones: Lista con valores categóricos con las predicciones de los distintos clasificadores base\n",
        "  :param pos_label: Valor considerado la clase positiva. Por defecto se considera el valor 1.\n",
        "   \n",
        "  :return: Probabilidad predicha de pertenencia a la clase positiva\n",
        "  '''\n",
        "  # COMPLETAR AQUI\n",
        "\n",
        "  num_true_positive = 0\n",
        "  \n",
        "  for pre in predicciones:\n",
        "\n",
        "    if pre == pos_label:\n",
        "\n",
        "      num_true_positive += 1\n",
        "  \n",
        "  return num_true_positive/len(predicciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7FAAJlXGHcO"
      },
      "source": [
        "## 2. Combinación de probabilidades (0.5 puntos)\n",
        "En esta sección implementaremos otra función de combinación de predicciones, para clasificadores que proporcionan probabilidades en lugar de únicamente la clase categórica.\n",
        "\n",
        "La función debe seguir el siguiente prototipo: ``comb_probabilidades(proba)``; donde el parámetro ``proba`` será una lista con las probabilidades predichas de pertenencia a la clase positiva por cada uno de los clasificadores base. La función debe devolver un único valor, que sea el de la probabilidad estimada por el ensemble de pertenencia a la clase positiva.\n",
        "\n",
        "Por ejemplo, si la función recibe la lista ``[0.3, 0.6, 0.8, 0.45, 0.7]``, debe devolver 0.57, que es la media de dichos valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HVV_5SHTIA_5"
      },
      "outputs": [],
      "source": [
        "def comb_probabilidades(proba):\n",
        "  '''\n",
        "  Devuelve la probabilidad de pertenencia a la clase positiva predicha por el \n",
        "    ensemble para un patrón, a partir de las probabilidades predichas por cada \n",
        "    clasificador base.\n",
        "\n",
        "  :param proba: Lista con las probabilidades de pertenencia a la clase positiva predichas por cada clasificador base\n",
        "   \n",
        "  :return: Probabilidad de pertenencia a la clase positiva predicha por el ensemble\n",
        "  '''\n",
        "  # COMPLETAR AQUI\n",
        "  import numpy as np\n",
        "  \n",
        "  return np.mean(proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RccxoIb7UX2G"
      },
      "source": [
        "## 3. Creación de ensemble tipo bagging (2.5 puntos)\n",
        "\n",
        "En esta sección, vamos a crear nuestro método de generación de ensembles, basado en el enfoque *bagging*. Además, para crear nuestro clasificador de ensemble, vamos a seguir la estructura sugerida por la librería *scikit-learn* para construir nuevos clasificadores compatibles con la propia librería. Aunque a continuación en la celda de implementación se dejan anotaciones para poder implementarlo correctamente, es recomendable tener en cuenta la [Guía de scikit-learn para el desarrollo de clasificadores propios](https://scikit-learn.org/stable/developers/develop.html).\n",
        "\n",
        "La selección del tipo clasificador base (knn, svm, árbol de decisión, ...) a utilizar dentro del ensemble, así como sus parámetros, serán decisión del alumno. Cualquier opción es válida, siempre que sea un clasificador de *scikit-learn* capaz de producir probabilidades como salida.\n",
        "\n",
        "En la siguiente celda, complete el código necesario para implementar el ensemble como clasificador de scikit-learn. Por defecto, se crea un clasificador llamado ``TemplateClassifier``. El estudiante debe modificar el nombre de la clase para darle a su clasificador el nombre que considere oportuno. \n",
        "\n",
        "A su vez, el clasificador debe contener, como mínimo, 4 funciones en su interior:\n",
        "*   ``__init__``: Recibe como parámetros todos los parámetros necesarios para crear el modelo. En nuestro caso debe recibir, como mínimo: el número de clasificadores base del ensemble, el tipo de combinación a utilizar (voto mayoritario o combinacion de probabilidades), el ratio de instancias a utilizar para entrenar cada clasificador base, la etiqueta de clase considerada como la clase positiva, y una variable ``random_state`` que actúe como semilla para números aleatorios para el entrenamiento posterior del modelo. \n",
        "  *  **IMPORTANTE:** Debe completar, o en esta misma celda de texto, o como documentación de la función en el código, qué significa cada uno de los parámetros que recibe la función, y que valores podría tomar.\n",
        "*   ``fit``: Esta función debe realizar los pasos necesarios para entrenar el modelo. Además de los pasos ya escritos dentro de la función, debe hacer lo necesario para entrenar el ensemble (es decir, entrenar cada uno de los clasificadores del ensemble).\n",
        "*   ``predict``: Esta función será la encargada de proporcionar predicción de clase categórica para cada patrón del conjunto de datos recibido. Consideramos por defecto un umbral de 0.5; es decir, si la función de combinación (voto mayoritario o combinación de predicciones) devuelve una probabilidad mayor o igual a 0.5, se predice la clase positiva, y la negativa en caso contrario. La salida debe ser una lista de valores categóricos que correspondan con la predicción de clase.\n",
        "*   ``predict_proba``: Esta función será la encargada de proporcionar la predicción de pertenencia a la clase positiva en forma de probabilidad, para cada patrón del conjunto de datos recibido.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tOoXIMj5rAwv"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import euclidean_distances\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "class BaggingEnsembleModel():\n",
        "  def __init__(self, n_models=10, combination='voting', ratio=0.7, pos_label=\"R\", negative_label=\"M\", random_state=0):\n",
        "    \n",
        "    # Asignar el parámetro n_models como parte de la clase\n",
        "    self.n_models = n_models\n",
        "    \n",
        "    # La funcion debe recibir más parámetros; este es solo un ejemplo.\n",
        "    #   Modifique la lista de parámetros de la función a lo especificado \n",
        "    #   anteriormente.\n",
        "\n",
        "    # COMPLETAR AQUI FUNCIÓN __init__\n",
        "    self.combination = combination\n",
        "    \n",
        "    self.ratio = ratio\n",
        "\n",
        "    self.pos_label = pos_label\n",
        "\n",
        "    self.y_ = negative_label\n",
        "\n",
        "    self.random_state = random_state\n",
        "\n",
        "    self.models = []\n",
        "\n",
        "    # La función __init__ no devuelve nada\n",
        "    \n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Comprobar que X e y tienen la estructura correcta\n",
        "    X, y = check_X_y(X, y)\n",
        "\n",
        "    # Almacenar los valores de clase durante el entrenamiento\n",
        "    self.classes_ = unique_labels(y)\n",
        "\n",
        "    # COMPLETAR AQUI FUNCIÓN fit --> Entrenamiento de clasificadores base\n",
        "    #   Para ello tenga en cuenta que debería considerar, al menos, los \n",
        "    #   parámetros: n_models, ratio, y random_state\n",
        "\n",
        "    for bag in range(self.n_models):\n",
        "\n",
        "      muestra = np.random.choice(np.arange(X.shape[0]), size = X.shape[0], replace=True)\n",
        "\n",
        "      X_bag = X[muestra]\n",
        "\n",
        "      y_bag = y[muestra]\n",
        "\n",
        "      model = SVC(C=self.ratio, random_state=self.random_state, probability=True)\n",
        "\n",
        "      model.fit(X_bag, y_bag)\n",
        "      \n",
        "      self.models.append(model)\n",
        "\n",
        "    # La función fit debe devolver siempre el propio clasificador (self)\n",
        "    return self\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Comprobar si se ha llamado a la función fit antes de a predict\n",
        "    check_is_fitted(self)\n",
        "\n",
        "    # Comprobar la estructura de entrada\n",
        "    X = check_array(X)\n",
        "\n",
        "    # Obtener la clase negativa (en escenario binario)\n",
        "    neg_label = list(set(np.unique(self.y_)) - set([self.pos_label]))[0]\n",
        "\n",
        "    # COMPLETAR AQUI FUNCIÓN predict\n",
        "    #   Para cada patrón de test debe combinar las salidas de los clasificadores\n",
        "    #   base, y proporcionar la salida final\n",
        "\n",
        "    predict = []\n",
        "\n",
        "    for i, model in enumerate(self.models):\n",
        "\n",
        "      if self.combination == \"voting\":\n",
        "\n",
        "        pred = voto_mayoritario(model.predict(X))\n",
        "\n",
        "      else:\n",
        "\n",
        "        pred = comb_probabilidades(model.predict_proba(X))\n",
        "      \n",
        "      if pred > 0.5:\n",
        "\n",
        "        predict.append(self.pos_label)\n",
        "        \n",
        "      else:\n",
        "\n",
        "        predict.append(neg_label)\n",
        "\n",
        "    # La función predict debe devolver una lista de valores categóricos\n",
        "    return predict\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    # COMPLETAR AQUI FUNCIÓN predict_proba\n",
        "\n",
        "    predict_proba = self.model.predict_proba(X)\n",
        "    # La función predict_proba debe devolver una lista de probabilidades\n",
        "\n",
        "    return predict_proba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGqTXzM-6hS"
      },
      "source": [
        "## 4. Estudio experimental y análisis (1.5 puntos)\n",
        "\n",
        "En esta sección, se pretende que el estudiante **implemente** un estudio experimental, **analice** sus resultados y **comente** los resultados y conclusiones obtenidas. Para ello, puede utilizar una o varias celdas de código, como considere que queda más limpio. También puede utilizar celdas de texto si lo considera necesario para el análisis de resultados.\n",
        "\n",
        "Se pretende que el estudio experimental sirva para **analizar el comportamiento del ensemble** en cuanto a **varios aspectos**: número de clasificadores base, método de combinación, y ratio de instancias utilizadas para entrenar cada modelo.\n",
        "\n",
        "Tras analizar esos resultados, debe escoger la mejor combinación de esos parámetros, y compararlo con un modelo que sea del mismo tipo y parámetros que los clasificadores base del ensemble (por ejemplo, si el ensemble utiliza árboles de decisión de clasificador base, comparar contra un único árbol de decisión), pero entrenado utilizando todo el conjunto de entrenamiento. Analice el rendimiento comparado de ambos métodos (ensemble y clasificador simple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vybqZRywrzct"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'reshape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/0n/nxywfqj174j8jrc5w4btcbb40000gn/T/ipykernel_14922/2290546242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingEnsembleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'probabilidad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"R\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/0n/nxywfqj174j8jrc5w4btcbb40000gn/T/ipykernel_14922/872860309.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mX_bag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmuestra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0my_bag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmuestra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'reshape'"
          ]
        }
      ],
      "source": [
        "# COMPLETAR AQUI\n",
        "\n",
        "model = BaggingEnsembleModel(n_models=10, combination='probabilidad', ratio=0.7, pos_label=\"R\", random_state=0)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MetodosPredictivos-TareaSemana5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
